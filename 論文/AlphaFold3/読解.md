
# Abstract
    AlphaFoldはタンパク質のモデリングに大きな影響を与えた。ここでは, タンパク質, 核酸, 低分子, 修飾された残基の構造を予測可能なAlphaFold3を紹介する。AlphaFold3は, ドッキングやタンパク質と核酸の複合構造予測などにおいて, それぞれのタスクに特化したモデルを上回る性能を示した。この結果は, 生物分子空間をまたぐモデリングが1つの深層学習フレームワークでモデリング可能であることを示している。
The introduction of AlphaFold 21 has spurred a revolution in modelling the structure of proteins and their interactions, enabling a huge range of applications in protein modelling and design2–6. Here we describe our AlphaFold 3 model with a substantially updated diffusion-based architecture that is capable of predicting the joint structure of complexes including proteins, nucleic acids, small molecules, ions and modified residues. The new AlphaFold model demonstrates substantially improved accuracy over many previous specialized tools: far greater accuracy for protein–ligand interactions compared with state-of-the-art docking tools, much higher accuracy for protein–nucleic acid interactions compared with nucleic-acid-specific predictors and substantially higher antibody–antigen prediction accuracy compared with AlphaFold-Multimer v.2.37,8. Together, these results show that high-accuracy modelling across biomolecular space is possible within a single unified deep-learning framework.

# main
    1a, 1b, 1c, 1d, 2a, 2b

    複合体のモデリングは生体反応の理解や治療法の開発に重要である。AlphaFold1によって構造予測は大きく進展し, AlphaFold2にもとづいてさまざまな研究が行われている。これまでに, 単純な入力の変更により精度が大幅に向上すること, タンパク質間の相互作用を特別に学習させることで精度が向上することが示されている。
Accurate models of biological complexes are critical to our understanding of cellular functions and for the rational design of therapeutics2–4,9. Enormous progress has been achieved in protein structure prediction with the development of AlphaFold1, and the field has grown tremendously with a number of later methods that build on the ideas and techniques of AlphaFold 2 (AF2)10–12. Almost immediately after AlphaFold became available, it was shown that simple input modifications would enable surprisingly accurate protein interaction predictions13–15 and that training AF2 specifically for protein inter- action prediction yielded a highly accurate system7.

    これらの成功を受け, リガンド, イオン, 核酸などを含む複合体の構造を予測できないかという話になる。これまで特定の相互作用に注目したモデルは作られてきており, また同時に開発された一般的な手法もある(=alphafold,29)。しかし, これらの手法の多くは特定の相互作用に注目しているため, 現実のさまざまな分子の複合体のモデリングには使えない。
These successes lead to the question of whether it is possible to accurately predict the structure of complexes containing a much wider range of biomolecules, including ligands, ions, nucleic acids and modified residues, within a deep-learning framework. A wide range of predictors for various specific interaction types has been developed16–28, as well as one generalist method developed concurrently with the present work29, but the accuracy of such deep-learning attempts has been mixed and often below that of physics-inspired methods30,31. Almost all of these methods are also highly specialized to particular interaction types and cannot predict the structure of general biomo- lecular complexes containing many types of entities.
    これらの成功は、リガンド、イオン、核酸、修飾残基など、より広範な生体分子を含む複合体の構造を、深層学習の枠組みで正確に予測することが可能かどうかという疑問につながる。様々な特定の相互作用タイプに対する幅広い予測手法が開発されてきた16-28。また、本研究と同時に開発された一般論的な手法もある29。しかし、このような深層学習の試みの精度はまちまちで、物理学にヒントを得た手法の精度を下回ることが多い30,31。また、これらの手法のほとんどすべてが、特定の相互作用タイプに高度に特化しており、多くのタイプの実体を含む一般的な生体分子複合体の構造を予測することはできない。

    ここでは,  PDBに存在するすべての分子種を予測できるAF3を紹介する(図1a,b)。1つのカテゴリを除き, 特定タスクに特化した手法を上回る精度を示している。
Here we present AlphaFold 3 (AF3)—a model that is capable of high-accuracy prediction of complexes containing nearly all molecular types present in the Protein Data Bank32 (PDB) (Fig. 1a,b). In all but one category, it achieves a substantially higher performance than strong methods that specialize in just the given task (Fig. 1c and Extended Data Table 1), including higher accuracy at protein structure and the structure of protein–protein interactions.
    ここでは、Protein Data Bank32（PDB）に存在するほぼすべての分子タイプを含む複合体を高精度に予測できるモデル、AlphaFold 3（AF3）を紹介する（図1a,b）。1つのカテゴリーを除くすべてにおいて、タンパク質構造やタンパク質間相互作用の構造において高い精度を示すなど、与えられたタスクだけに特化した強力な手法よりも大幅に高い性能を達成している（図1cおよび拡張データ表1）。

    (1d)AF3は, 学習のデータ効率(...何?)を向上させるため, AF2の構造を改善した。
    (2a)evoformerをよりシンプルなpairformerにすることで, MSAアラインメント処理の量を減らした。
    (2b)AF2はフレームと側鎖のねじれ角で動作していたが, AF3は原子座標を直接予測する。これにより, 特殊な結合も考慮することができる。
This is achieved by a substantial evolution of the AF2 architec- ture and training procedure (Fig. 1d) both to accommodate more general chemical structures and to improve the data efficiency of learning. The system reduces the amount of multiple-sequence alignment (MSA) processing by replacing the AF2 evoformer with the simpler pairformer module (Fig. 2a). Furthermore it directly predicts the raw atom coordinates with a diffusion module, replac- ing the AF2 structure module that operated on amino-acid-specific frames and side-chain torsion angles (Fig. 2b). The multiscale nature of the diffusion process (low noise levels induce the net- work to improve local structure) also enable us to eliminate stereochemical losses and most special handling of bonding pat- terns in the network, easily accommodating arbitrary chemical components.
    これは、より一般的な化学構造に対応し、学習のデータ効率を向上させるために、AF2のアーキテクチャと学習手順（図1d）を大幅に進化させることで実現した。このシステムでは、AF2 evoformerをよりシンプルなpairformerモジュールに置き換えることで、多重配列アライメント（MSA）処理の量を減らしている（図2a）。さらに、アミノ酸固有のフレームと側鎖のねじれ角で動作していたAF2構造モジュールに代わって、拡散モジュールで生の原子座標を直接予測する（図2b）。拡散プロセスのマルチスケールな性質（低ノイズレベルが局所構造を改善するためにネットワークを誘導する）により、立体化学的な損失やネットワーク内の結合パターンの最も特殊な取り扱いを排除することができ、任意の化学成分に容易に対応することができる。


# Network architecture and training
    1d, 2a, 2b, S1, 2c, 2d, S2

    AF3の全体的な構造(図1d, SM3)はAF2と同じであり, 分子の複合体のペアごとの表現を更新する大きなトランクの後に, そのペア表現を使って明示的に原子座標を生成するstructure moduleが続いているが, それぞれの主な構成要素には大きな違いがある。
    この違いは, 例外処理をやりすぎることなく幅広い化合物を受け入れる必要があるということと, AF2に異なる修正を加えたときの性能を観察した結果によるものである。
    トランクでは, MSAのembedding blockが大幅に小さく簡単になるなど(SM3.3), MSAの処理が大幅に強調されなくなっている。
    AF2の元々のevoformerと比較すると, (何の?)ブロックの数が4つに減少し, MSA表現の処理は計算量の少ないpair-weighted averagingになっており, その後のステップではペア表現のみが用いられる。
    主要な処理ブロックとしては, AF2のevoformerが"pairformer"(図2a, SM3.6)になっている。
    pairformerはペア表現と単一の表現のみを処理する。MSA表現はここでは保持されず, 全てのMSA情報はペア表現を通じて伝達される。
    ペアの処理とブロック数(48)はAF2から大まかには変わっていない。
    得られたペア表現と単一配列の表現は, 入力の表現と共に, AF2のstructure moduleにあたる新しいdiffusion modelに渡される。
The overall structure of AF3 (Fig. 1d and Supplementary Methods 3) echoes that of AF2, with a large trunk evolving a pairwise representation of the chemical complex followed by a structure module that uses the pairwise representation to generate explicit atomic positions, but there are large differences in each major component. These modifications were driven both by the need to accommodate a wide range of chemical entities without excessive special casing and by observations of AF2 performance with different modifications. Within the trunk, MSA processing is substantially de-emphasized, with a much smaller and simpler MSA embedding block (Supplementary Methods 3.3). Compared with the original evoformer from AF2, the number of blocks is reduced to four, the processing of the MSA representation uses an inexpensive pair-weighted averaging and only the pair representation is used for later processing steps. The ‘pairformer’ (Fig. 2a and Supplementary Methods 3.6) replaces the evoformer of AF2 as the dominant processing block. It operates only on the pair representation and the single representation; the MSA representation is not retained and all information passes through the pair representation. The pair processing and the number of blocks (48) is largely unchanged from AF2. The resulting pair and single representation together with the input representation are passed to the new diffusion module (Fig. 2b) that replaces the structure module of AF2.
    AF3の全体的な構造（図1dと補足方法3）は、AF2と同じで、大きなトランクが化学複合体のペアワイズ表現を進化させ、その後にペアワイズ表現を使用して明示的な原子位置を生成する構造モジュールが続くが、各主要コンポーネントには大きな違いがある。これらの変更は、過度な特殊なケーシングを行わずに幅広い化学実体に対応する必要性と、異なる変更を行った場合のAF2の性能の観察の両方によって行われた。トランク内では、MSA処理が大幅に強調されなくなり、MSAエンベッディングブロックがより小さくシンプルになった（補足メソッド3.3）。AF2のオリジナルのevoformerと比較すると、ブロックの数は4つに減り、MSA表現の処理は安価なペア重み付け平均を使用し、ペア表現のみが後の処理ステップに使用される。ペアフォーマー」（図2aおよび補足方法3.6）は、AF2のエボフォーマーに代わる主要な処理ブロックである。MSA表現は保持されず、すべての情報はペア表現を通過する。ペア処理とブロック数（48）はAF2とほとんど変わらない。得られたペア表現と単一表現は、入力表現とともに、AF2の構造モジュールに代わる新しい拡散モジュール（図2b）に渡される。

    AF2ではhead部分を単純化しても精度にわずかしか影響がないことがわかっており, 一般的な分子グラフではねじれ表現を維持するとかなり複雑さが増すため, AF3のhead(拡散モジュール)は原子座標をそのまま処理することにした。モデルは普通にノイズをかけたデータをデノイズするように学習させる。 AF2では構造がvalidになるようにいろんな制約をつけていたが, AF3ではdenoisingモデルなので, 構造が不確かなばあいでも細かい座標を生成する。なので制約をかけなくてもvalidになり, かつ一般的な入力を受け取れるらしい。
    (34)と同様に, 不変性や等変性は必要ないことがわかったので, モデルを単純かするため省略した。

    拡散モジュール(図2b, SM3.7)は, 原子座標そのもの, および疎な抽象的なトークン表現(confidenceなど座標以外のheadに対応するもの?)を直接操作し, 回転するフレーム等は用いない。
    私たちは, AF2の構造モジュールの大部分を簡略化しても, 予測精度には控えめな影響しかないことを発見しており, (タンパク質について?)骨格フレームと残基のねじれ表現を保持すると一般の原子グラフに対してはかなり処理が複雑になる。
    また, AF2では出力構造の化学的妥当性を保つため, 立体化学的な法則の違反に対する損失項を慎重に調整する必要があった。
    私たちは, ノイズを加えた原子座標から本当の座標を予測するようモデルを訓練する標準的な拡散モデルの手法[33]を使った。
    このような課題設定では, 様々な長さのタンパク質構造を学習する必要がある。それによって, 小さなノイズを除去するタスクがとても局所的な立体化学の理解を重視し, 大きなノイズを除去するタスクが大きなスケールでの構造を重視する。
    推論時には, ランダムに生成したノイズを繰り返しノイズ除去することで最終的な構造を出力する。
    重要なことは, これは答えの分布を出力する生成的な学習過程であるということである。
    これはつまり, 局所的な構造について, モデルに自信がなくても細かな構造を出力する(例えば, 側鎖の結合についての構造(?))ということである。
    このため, 一般的なリガンドを全て処理しつつ, ねじれ角ベースで残基を表現したり, 構造の法則の違反項の設定を回避できる。
    最近の研究[34]と同様に, 私たちは分子全体の回転・並進に対する不変性・同変性は必要ないことを発見しており, モデルの簡略化のためそれらを省いた。
The diffusion module (Fig. 2b and Supplementary Methods 3.7) operates directly on raw atom coordinates, and on a coarse abstract token representation, without rotational frames or any equivariant process- ing. We had observed in AF2 that removing most of the complexity of the structure module had only a modest effect on the prediction accuracy, and maintaining the backbone frame and side-chain torsion representation add quite a bit of complexity for general molecular graphs. Similarly AF2 required carefully tuned stereochemical violation penalties during training to enforce chemical plausibility of the resulting structures. We use a relatively standard diffusion approach33 in which the diffusion model is trained to receive ‘noised’ atomic coordinates and then predict the true coordinates. This task requires the network to learn protein structure at a variety of length scales, whereby the denoising task at small noise emphasizes understanding very local stereochemistry and the denoising task at high noise emphasizes the large-scale structure of the system. At the inference time, random noise is sampled and then recurrently denoised to produce a final structure. Importantly, this is a generative training procedure that produces a distribution of answers. This means that, for each answer, the local structure will be sharply defined (for example, side-chain bond geometry) even when the network is uncertain about the positions. For this reason, we are able to avoid both torsion-based parametrizations of the residues and violation losses on the structure, while handling the full complexity of general ligands. Similarly to some recent work34, we find that no invariance or equivariance with respect to global rotations and translation of the molecule are required in the architecture and we therefore omit them to simplify the machine learning architecture.
    拡散モジュール（図2bと補足方法3.7）は、回転フレームや等変量処理を行わず、生の原子座標と粗い抽象トークン表現で直接動作する。AF2では、構造モジュールの複雑さの大部分を取り除いても、予測精度にはわずかな効果しかなく、一般的な分子グラフでは、骨格フレームと側鎖のねじれ表現を維持すると、かなり複雑さが増すことが観察されていました。同様に、AF2は、得られた構造の化学的妥当性を強化するために、学習中に注意深く調整された立体化学的違反ペナルティを必要とした。私たちは比較的標準的な拡散アプローチ33 を用いており、拡散モデルは「ノイズの入った」原子座標を受け取ってから真の座標を予測するように学習される。このタスクでは、ネットワークが様々な長さスケールでタンパク質構造を学習する必要があり、ノイズが小さい場合のノイズ除去タスクでは、非常に局所的な立体化学を理解することに重点が置かれ、ノイズが大きい場合のノイズ除去タスクでは、系の大規模な構造を理解することに重点が置かれる。推論時には、ランダムなノイズがサンプリングされ、最終的な構造を生成するために再帰的にノイズ除去される。重要なのは、これは生成的な学習手順であり、答えの分布を生成することである。これは、ネットワークが位置について不確かであっても、各回答について局所構造が鋭く定義されることを意味する（例えば、側鎖結合の幾何学）。このため、一般的なリガンドの複雑さを完全に扱いながら、残基のねじれベースのパラメトリゼーションと構造上の違反ロスの両方を回避することができる。最近のいくつかの研究34と同様に、分子の大域的な回転と平行移動に関する不変性や等変量性は必要ないことがわかったので、機械学習アーキテクチャーを単純化するために省略した。

    diffusionモデルは, 幻覚を見やすい, つまり何もない領域に新しい構造を作り出してしまいやすいことが欠点の1つだが, これを解決するためAlphaFold-Multimerを使って予測した構造で学習データをaugmentした。AF-Multimerでは非構造化領域は伸びたループとして表現されやすいので, それを学習させることで幻覚が大幅に減少した(EFig.1)

    生成的拡散モデルを採用する上で, いくつかの技術的課題に対処する必要があった。
    最も大きな問題は, 生成モデルがhallucinationを起こしやすいということである。それによってモデルは構造化されていない領域でもそれらしい構造を生成する可能性がある。
    この効果を打ち消すため, 私たちはAlphaFold-Multimer(v2.3)の予測結果で学習データを増幅するcross-distillationを行った。
    AF-multimerの予測結果では, 構造化されていない領域は長いループで表現されることが多く, それを学習させることでAF3にそのようなふるまいを模倣させるよう教えた。
    このcross-distillationにより, AF3のhallucinationは大幅に減少した(図E1にCAID 236ベンチマークデータセットについての無秩序な領域の予測結果を示している)。
The use of a generative diffusion approach comes with some technical challenges that we needed to address. The biggest issue is that generative models are prone to hallucination35, whereby the model may invent plausible-looking structure even in unstructured regions. To counteract this effect, we use a cross-distillation method in which we enrich the training data with structures predicted by AlphaFold-Multimer (v.2.3)7,8. In these structures, unstructured regions are typically represented by long extended loops instead of compact structures, and training on them ‘teaches’ AF3 to mimic this behaviour. This cross-distillation greatly reduced the hallucination behaviour of AF3 (Extended Data Fig. 1 for disorder prediction results on the CAID 236 benchmark set).
    生成的拡散アプローチの使用には、いくつかの技術的課題があり、それに対処する必要があった。最も大きな問題は、生成モデルは幻覚を見やすいということである35。これにより、モデルは、構造化されていない領域であっても、もっともらしく見える構造を作り出す可能性がある。この効果を打ち消すために、我々はAlphaFold-Multimer(v.2.3)7,8によって予測された構造で訓練データを豊かにする交差蒸留法を用いる。これらの構造では、非構造化領域はコンパクトな構造ではなく、長く伸びたループで表現されるのが一般的であり、このような構造でトレーニングすることで、AF3がこのような挙動を模倣するように「教える」のである。このクロスディスティレーションにより、AF3の幻覚挙動が大幅に減少した（CAID 236ベンチマークセットでの無秩序予測結果については、Extended Data Fig.）

    なんかよくわからんけどconfidence modelも学習したらしい。step数の荒い同じdiffusion modelを使ったとかなんとか。

    また, 私たちは最終的な構造の原子レベル, 及びペアごとの誤差を予測するconfidenceの指標も開発した。
    AF2では, 学習中に構造モジュールの誤差を直接回帰する(=回帰タスクとして学習する?)ことでこれを行っていた。
    しかし, 拡散の学習においては全体の構造生成ではなく拡散の各段階が学習されるため, この方法は使えない(2c)。
    これを解決するため, 学習中に全ての構造を生成するための(通常より大きなstepを使った)拡散'rollout'過程を開発した(2c)。
    予測されたこの構造を使い, 正解の鎖(の各残基?)とリガンド(の各原子?)を並べ替え, 確信度予測headを学習させるための予測精度の評価指標を計算した。
    確信度headは, ペア表現を使ってF2と同様に modified mocal distance difference test(pLDDT)とpredicted aligned error(PAE)行列を予測するほか, 予測構造の距離行列と正解の構造の距離行列の誤差であるdistance error matrix(PDE)も予測する(詳細はSM4.3にある)。

        要は, 訓練中に(計算量を簡略化するため)stepを荒くしたざっくりとした予測を行って, それと正解の誤差を予測させたということだと思う。
We also developed confidence measures that predict the atom-level and pairwise errors in our final structures. In AF2, this was done directly by regressing the error in the output of the structure module during training. However, this procedure is not applicable to diffusion training, as only a single step of the diffusion is trained instead of a full-structure generation (Fig. 2c). To remedy this, we developed a diffusion ‘rollout’ procedure for the full-structure prediction generation during training (using a larger step size than normal; Fig. 2c (mini-rollout)). This predicted structure is then used to permute the symmetric ground-truth chains and ligands, and to compute the performance metrics to train the confidence head. The confidence head uses the pairwise representation to predict a modified local distance difference test (pLDDT) and a predicted aligned error (PAE) matrix as in AF2, as well as a distance error matrix (PDE), which is the error in the distance matrix of the predicted structure as compared to the true structure (details are provided in Supplementary Methods 4.3).
    また、最終的な構造における原子レベルおよびペアごとの誤差を予測する信頼度指標を開発した。AF2では、学習中の構造モジュールの出力の誤差を回帰することにより、これを直接行いました。しかし、この方法は拡散のトレーニングには適用できません。なぜなら、完全な構造生成ではなく、拡散のシングルステップのみがトレーニングされるからです（図2c）。この問題を解決するために、私たちはトレーニング中の完全構造予測生成のための拡散「ロールアウト」手順を開発しました（通常よりも大きなステップサイズを使用；図2c（ミニロールアウト））。この事前予測された構造を用いて、対称的なグランドトゥルース鎖とリガンドを並べ替え、パフォーマンスメトリックを計算し、信頼性ヘッドをトレーニングする。確信度ヘッドはペアワイズ表現を使って、AF2と同様に修正局所距離差検定（pLDDT）と予測整列誤差（PAE）行列を予測し、さらに予測構造の距離行列の真の構造に対する誤差である距離誤差行列（PDE）を予測する（詳細は補足方法4.3に記載）。

    (2d)局所構造は早期に学習され, やがて過学習する一方, 全体構造の学習には時間がかかった。このためepochによってサンプル数, ロスの重みなどを変え, 最適なチェックポイントを探した。

    図2dは, 最初の学習(=finetuningでない学習?)中, モデルは局所的な構造を早期に予測できるようになる(鎖内の精度の評価指標は全てすぐ上昇し, 性能の最大値の97%に20000step以内に到達する)ものの, 全体的な集まりを学習するにはそれよりかなり長いstepがかかる(界面についての評価指標はゆっくりと上昇し, タンパク質間のインターフェースのLDDTは60000step以上たってから最大性能の97%に到達している)。
    AF3の開発中, 私たちはモデルのいくつかの能力が早い段階で最大に達し, その後他の能力が学習中であるにもかかわらず, (おそらくはこのモデルの能力に対して限られた数の学習データにオーバーフィッティングしたため)能力が低下し始めることを観測した。
    これへの対処として, 私たちは対応する学習データのサンプリング確率を増やし/減らし(SM2.5.1), また最も良いモデルのチェックポイントを選ぶため, 上記全ての評価指標, 及びいくつかの追加の評価指標(表S7)の加重平均を使ってearly stoppingを行った。
    大きなcrop sizeを使ったfinetuningの段階では全ての指標が改善し, 特にタンパク質間の界面の精度が上昇した(図E2..どれ?)
Figure 2d shows that, during initial training, the model learns quickly to predict the local structures (all intrachain metrics go up quickly and reach 97% of the maximum performance within the first 20,000 training steps), while the model needs considerably longer to learn the global constellation (the interface metrics go up slowly and protein–protein interface LDDT passes the 97% bar only after 60,000 steps). During AF3 development, we observed that some model abilities topped out relatively early and started to decline (most likely due to overfitting to the limited number of training samples for this capability), while other abilities were still undertrained. We addressed this by increasing or decreasing the sampling probability for the corresponding training sets (Supplementary Methods 2.5.1) and by performing early stopping using a weighted average of all of the above metrics and some additional metrics to select the best model checkpoint (Supplementary Table 7). The fine-tuning stages with the larger crop sizes improve the model on all metrics with an especially high uplift on protein–protein interfaces (Extended Data Fig. 2).
    図2dは、初期トレーニングの間、モデルは局所構造を予測するために素早く学習する（すべての鎖内メトリクスは素早く上昇し、最初の20,000トレーニングステップ内で最大性能の97%に達する）一方で、モデルはグローバルなコンステレーションを学習するためにかなり長い時間を必要とする（界面メトリクスはゆっくりと上昇し、タンパク質-タンパク質界面LDDTは60,000ステップ後に初めて97%のバーを通過する）ことを示している。AF3の開発中、いくつかのモデルの能力が比較的早い段階で頭打ちになり、低下し始めることが観察されました（この能力に対するトレーニングサンプルの数が限られていたため、オーバーフィッティングが起こった可能性が高い）。私たちは、対応するトレーニングセットのサンプリング確率を増減させ（補足的方法2.5.1）、上記のすべてのメトリクスの加重平均といくつかの追加メトリクスの加重平均を使用して早期停止を実行し、最適なモデルのチェックポイントを選択することにより、これに対処しました（補足表7）。クロップサイズを大きくしたファインチューニングステージでは、全てのメトリクスでモデルが改善され、特にタンパク質-タンパク質界面での上昇率が高い（Extended Data Fig.）

# Accuracy across complex types
    3, 1c, E3, E4b-f, E4a, 1c, 3a, E5a, 1c, E5b, E6, 5a

    Fig.3 では, 予測の例を示す。これらは学習データとの配列が近いかどうかという観点で選んだ(?)。選び方についてはsup.method 8.1を参照とのこと

    AF3は入力のポリマー配列, 残基修飾情報, リガンドSMILESから構造を予測する。図3では, 生物学的に重要で疾患の治療に関連するいくつものん複合体に一般化できるというモデルの能力を強調する予測例を示す。
    それぞれの鎖と相互作用の学習データに対する類似性の観点から, 新規性を考慮してこれらの例を選んでいる。
AF3 can predict structures from input polymer sequences, residue modifications and ligand SMILES (simplified molecular-input line-entry system). In Fig. 3 we show  a selection of examples highlighting the ability of the model to generalize to a number of biologically important and therapeutically relevant modalities. In selecting these examples, we considered novelty in terms of the similarity of individual chains and interfaces to the training set (additional information is provided in Supplementary Methods 8.1).
    AF3は、入力されたポリマー配列、残基修飾、およびリガンドSMILES（simplified molecular-input line-entry system）から構造を予測することができる。Fig.3では、このモデルが生物学的に重要で、治療に関連する多くのモダリティに汎化できることを強調した例を示している。これらの例を選択する際、個々の鎖とインターフェイスのトレーニングセットとの類似性という観点から新規性を考慮した（追加情報はSupplementary Methods 8.1に記載）。

    (1c)PoseBustersデータセットを使って評価したところ, vinaのような古典的手法や, RFAAを上回る予測精度を示した。(古典的な手法は?)正解のタンパク質構造をリークするにもかかわらず, それも上回った(?)。PoseBustersは2021年以降のデータを使っていたが, これまで2021年までを学習データとして使っていたので, 新しくデータを取って学習しなおした。
    (以下よくわからん)

    私たちは, 各組み合わせの複合体について, 近年のその相互作用に特化したベンチマークで本モデルの性能を評価した(図1c, 表E1)。タンパク質とリガンドの接触面についての性能は, 2021年以降にPDBに登録された428のタンパク質-リガンド構造からなるPoseBustersデータで評価した。
    本モデルのbaselineは2021年までのデータを学習データのcutoffとしているので, より速いカットオフまでのデータでモデルを別途訓練した(Methods)。
    PoseBustersデータセットに対する精度は, タンパク質とリガンドのペアを, タンパク質についてalignした(=正解のタンパク質と座標がなるべく一致するように姿勢・位置を調整した?)ときのリガンドのRMSEが2A以下だったものの割合として示している。
    ベースラインのモデルは, タンパク質のアミノ酸配列とSMILESのみを入力として使うものと, 追加でタンパク質-リガンド複合体構造からの情報をリークして使うもの(表によると, holo protein構造(=リガンドと結合したタンパク質からリガンドを抜いたもの?補酵素などと結合したもの?)を使うものと, (加えて?)ポケットの残基を指定するものがある)を用いている。
    昔からあるドッキング手法は, 実際に用いる場合は使えないにもかかわらず後者の豊富な情報を使っている。
    にもかかわらず, 何も構造情報を使わなくてもAF3はVinaのような以前からある典型的なドッキングツールを大きく上回る結果を出している(フィッシャーの直接確率検定でp=2.27x10^13)
    また, RoseTTAFold All-Atomのように構造情報を使わないドッキング手法を大きく上回っている(p=4.45x10^-25)。
    図E3は, AF3が正確に予測できたが, VinaとGoldはできなかった3つの例を示している。
    PoseBustersの解析(=RMSDだけでなく, 予測がvalidかなどの解析?)は, PoseBustersデータに含まれる構造で学習しないよう2019/9/30日までのデータで学習したモデルについて行っている(...validationは?)
    RFAAの結果と比較するため, PoseBusters version 1を使って評価した。
    version2(結晶のcontactがベンチマークから除かれている)での結果は, quality metrics(..validかどうかの指標?)も含めて図E4b-fと表E1にある。
    私たちは(diffusion guidanceなどではなく)いくつかのseedで予測構造を生成し, キラリティが正しくリガンドとタンパク質がぶつかっていないものを選択したが, 典型的には立体化学に妥当な構造を生成していた。
    また本論文のモデルとは別に, 近年の研究[24,26]で行われているように"ポケット情報"を入力するモデルも学習した(結果は図E4aに示している)。
We evaluated the performance of the system on recent interface-specific benchmarks for each complex type (Fig. 1c and Extended Data Table 1). Performance on protein–ligand interfaces was evalu- ated on the PoseBusters benchmark set, which is composed of 428 protein–ligand structures released to the PDB in 2021 or later. As our standard training cut-off date is in 2021, we trained a separate AF3 model with an earlier training-set cutoff (Methods). Accuracy on the PoseBusters set is reported as the percentage of protein–ligand pairs with pocket-aligned ligand root mean squared deviation (r.m.s.d.) of less than 2 Å. The baseline models come in two categories: those that use only protein sequence and ligand SMILES as an input and those that additionally leak information from the solved protein–ligand test structure. Traditional docking methods use the latter privileged information, even though that information would not be available in real-world use cases. Even so, AF3 greatly outperforms classical docking tools such as Vina37,38 even while not using any structural inputs (Fisher’s exact test, P = 2.27 × 10−13) and greatly outperforms all other true blind docking like RoseTTAFold All-Atom (P = 4.45 × 10−25). Extended Data Fig. 3 shows three examples in which AF3 achieves accurate predictions but docking tools Vina and Gold do not37. PoseBusters analysis was performed using a training cut-off of 30 September 2019 for AF3 to ensure that the model was not trained on any PoseBusters structures. To compare with the RoseTTAFold All-Atom results, we used PoseBusters version 1. Version 2 (crystal contacts removed from the benchmark set) results including quality metrics are shown in Extended Data Fig. 4b–f and Extended Data Table 1. We use multiple seeds to ensure correct chirality and avoid slight protein–ligand clashing (as opposed to a method like diffusion guidance to enforce) but we are typically able to produce high-quality stereochemistry. Separately, we also train a version of AF3 that receives the ‘pocket information’ as used in some recent deep-learning work24,26 (the results are shown in Extended Data Fig. 4a).
    各複合体タイプについて、最近の界面特異的ベンチマークでシステムの性能を評価した（図1cと拡張データ表1）。タンパク質-リガンド界面の性能は、2021年以降にPDBに公開された428のタンパク質-リガンド構造からなるPoseBustersベンチマークセットで評価した。このベンチマークセットは、2021年以降にPDBに公開された428のタンパク質-リガンド構造から構成されている。標準的なトレーニングのカットオフ日は2021年であるため、トレーニングセットのカットオフ日を早めて別のAF3モデルをトレーニングした（Methods）。PoseBustersセットでの精度は、ポケットアライメントされたリガンドの二乗平均平方根偏差（r.m.s.d.）が2Å未満であったタンパク質-リガンドペアの割合として報告されている。ベースラインモデルには、入力としてタンパク質配列とリガンドSMILESのみを使用するものと、解決されたタンパク質-リガンドテスト構造からの情報を追加的にリークするものの2つのカテゴリーがある。伝統的なドッキング手法では、後者の特権的な 情報を使用するが、実際の使用例ではそのような情報は得 られない。それにもかかわらず、AF3 は、Vina37,38 のような古典的なドッキングツールを、構造入力を使用しない場合で も大きく上回り（フィッシャーの正確検定、P = 2.27 × 10-13）、RoseTTAFold All-Atom のような他のすべての真のブラインドドッキングを大きく上回った（P = 4.45 × 10-25）。拡張データ 図3は、AF3は正確な予測を達成したが、ドッキングツールのVinaとGoldは達成できなかった3つの例を示している37。PoseBusters解析は、モデルがPoseBusters構造で学習されていないことを確実にするため、AF3の学習カットオフを2019年9月30日として実施した。RoseTTAFold All-Atomの結果と比較するために、PoseBustersバージョン1を使用した。品質評価指標を含むバージョン2（ベンチマークセットから結晶コンタクトを削除）の結果は、Extended Data Fig.4b-fとExtended Data Table 1に示されています。正しいキラリティを確保し、タンパク質とリガンドのわずかな衝突を避けるために複数のシードを使用しています（拡散誘導のような強制的な方法とは対照的です）が、通常、高品質の立体化学を生成することができます。これとは別に、いくつかの最近のディープラーニング研究で使用されているような「ポケット情報」を受け取るバージョンのAF3もトレーニングしている24,26（結果はExtended Data Fig.4aに示されている）。

    (1c)AF3は, 核酸とタンパク質の複合体構造予測においてRFNAを上回った。
    RFNAは評価に1000残基以下の構造しか使っていないので, そのようなデータセットで評価した。
    AF3は数千残基のタンパク質-核酸複合体構造も予測できる。
    今回AF3とRFAAを直接比較はしなかったが, 29によるとRFAAはRFNAよりやや性能が低い。

    タンパク質と核酸の複合体や, RNAの構造も, RFNAより正確に予測した(1c2番目)。
    RFNAは1000残基以下の構造について評価しているので, 私たちも自分たちの直近のPDBの評価データのうち1000残基以下のもののみで評価した。
    図3aに例を示すように, AF3は何千もの残基のあるタンパク質-核酸複合体の構造も予測できる。
    私たちはRFAAと直接比較することはしていないが, ベンチマークによると核酸予測においてはRFAAはRFNAより少し精度が低い[29]。
AF3 predicts protein–nucleic complexes and RNA structures with higher accuracy than RoseTTAFold2NA15 (Fig. 1c (second plot)). As RoseTTAFold2NA is validated only on structures below 1,000 residues, we use only structures below 1,000 residues from our recent PDB evaluation set for this comparison (Methods). AF3 is able to predict protein–nucleic structures with thousands of residues, an example of which is shown in Fig. 3a. Note that we do not compare directly to RoseTTAFold All-Atom, but benchmarks indicate that RoseTTAFold All-Atom is slightly less accurate than RoseTTAFold2NA for nucleic acid predictions29.
    AF3はRoseTTAFold2NA15よりも高い精度でタンパク質-核複合体とRNA構造を予測する（図1c（2番目のプロット））。RoseTTAFold2DNAは1,000残基以下の構造に対してのみ検証されているため、この比較には最近のPDB評価セットから1,000残基以下の構造のみを使用した（Methods）。AF3は数千残基のタンパク質-核構造を予測することができ、その例を図3aに示す。RoseTTAFold All-Atomと直接比較はしていないが、ベンチマークによると、核酸予測においてRoseTTAFold All-AtomはRoseTTAFold2NAより若干精度が低い29。


    (S5a, 1c中央左)AF3を, CASP15のRNAデータセットでも評価し, RFNA, 及びCASP15で最もよかったAIベースの手法のAIchemy_RNA, human-expert-aidedも含む最もよかった手法のAIchemy_RNA2と比較したところ, AIchemy_RNA2に次ぐパフォーマンスだった。
    データセットサイズが限られるため有意差検定は行わなかった。
    (S5b) タンパク質のない, 核酸のみの構造の予測精度について書いた。

    私たちは, AF3をCASP15で一般に公開されている10のRNAのターゲットについての性能も評価した。RoseTTAFold2NAとAIchemy_RNA(CASP15においてAIベースの手法で最も良かったもの)に対し, それぞれ共通の予測に対し平均で上回った(E5aだと, 10のターゲットのいくつかについてRFNA, AIchemyが結果を出力できていなかったので, それらを除いたターゲットについての平均でそれぞれ上回ったということだと思われる, 詳細な結果は図E5a)。人間の専門家の助けを借りた(=予測結果を人間が修正した?)手法で最も良かったAIchemy_rna2は上回ることができなかった(図1c中央左)。
    データセットサイズが限られているので, ここでは有意差検定の結果は報告しない。
    タンパク質がなく, 核酸のみの構造の予測については, 図5bにさらなる分析を示している。
We also evaluated AF3 performance on the ten publicly available Critical Assessment of Structure Prediction 15 (CASP15) RNA targets: we achieve a higher average performance than RoseTTAFold2NA and AIchemy_RNA27 (the best AI-based submission in CASP1518,31) on the respective common subsets of our and their predictions (detailed results are shown in Extended Data Fig. 5a). We did not reach the performance of the best human-expert-aided CASP15 submission AIchemy_RNA239 (Fig. 1c (centre left)). Owing to limited dataset sizes, we do not report significance test statistics here. Further analysis of the accuracy of predicting nucleic acids alone (without proteins) is shown in Extended Data Fig. 5b.
    また、一般に公開されている10のCritical Assessment of Structure Prediction 15 (CASP15)のRNAターゲットについて、AF3の性能を評価した。RoseTTAFold2NAとAIchemy_RNA27（CASP15で最も優れたAIベースのサブセット18,31）よりも高い平均性能を達成した（詳細な結果はExtended Data Fig.5aに示す）。我々は、CASP15で最も優れたAIを用いたAIchemy_RNA239（図1c（中央左））のパフォーマンスには到達しなかった。データセットサイズが限られているため、ここでは有意差検定の統計量は報告しない。核酸のみ（タンパク質なし）の予測精度のさらなる分析は、拡張データFig.

    (1c中央右)共有結合修飾に対してもAF3は正確に予測した。RMSD<2Aだったものの割合を示している。 PoseBustersデータセットにならい, ある程度正確なデータのみで評価した。また学習データとの配列の類似性によるフィルタリングは行なっていない。
    その他いろいろなデータ処理について?

    共有結合修飾(リガンドの結合, 糖鎖付加, アミノ酸残基や核酸塩基の修飾)もAF3は正確に予測できた(図1c中央右)。
    修飾はタンパク質, DNA, RNA全ての残基への修飾を含む。
    予測精度はポケット(...ってどこ?)のRMSDが2Å未満だったものの割合で示している。
    (PoseBustersと同様に)私たちはリガンドや糖鎖が結合したデータについて, 高品質なデータのみをフィルタリングした。
    具体的には, 高品質なリガンドデータ(model qualityがRCSB全体の?上半分のみのもの)のみを加えた。
    PoseBustersデータと同様に, リガンドや糖鎖が共有結合したデータは学習データとの類似性によるフィルタリングは行わなかった。
    リガンドや糖鎖が結合したポリマー鎖の類似性(polymer template similarityが40以下かで類似しているかどうかを判断する)によるフィルタリングでは, リガンドについては5つのクラスタ, 糖鎖については7つのクラスタしか作らなかった(から, 学習データとのフィルタリングは行わなかった?しかしなぜクラスタが少ないとフィルタリングしないのか?)。
    複数残基の糖鎖(複数の糖が結合しているのか, 糖鎖が複数の残基に結合しているのか?)は, RCSB-PDBにranking_model_fitがなかったので, データに含めなかった。
    複数残基のグリカンに対する予測精度は, RMSD<2Aが42.1%(n=131クラスタ)で, 1つの残基のグリカンの予測精度(46.1%, n=167)よりやや低かった。修飾された残基のデータセットも, 他のポリマーデータセットと同様にフィルタリングした。
        つまり, 学習データセットと類似性の低いポリマー鎖のみ含んでいる(Methods)。
    詳細な結果については表E1を, リン酸化が予測に与える影響を含め, 共有結合修飾されたタンパク質, RNA, DNAの予測例については図E6を参照
Covalent modifications (bonded ligands, glycosylation, and modified protein residues and nucleic acid bases) are also accurately predicted by AF3 (Fig. 1c (centre right)). Modifications include those to any polymer residue (protein, RNA or DNA). We report accuracy as the percentage of successful predictions (pocket r.m.s.d. < 2 Å). We apply quality filters to the bonded ligands and glycosylation dataset (as does PoseBusters): we include only ligands with high-quality experimental data (ranking_model_fit > 0.5, according to the RCSB structure validation report, that is, X-ray structures with a model quality above the median). As with the PoseBusters set, the bonded ligands and glycosylation datasets are not filtered by homology to the training dataset. Filtering on the basis of the bound polymer chain homology (using polymer template similarity < 40) yielded only five clusters for bonded ligands and seven clusters for glycosylation. We exclude multi-residue glycans here because the RCSB validation report does not provide a ranking_model_fit value for them. The percentage of successful predictions (pocket r.m.s.d. < 2 Å) for multi-residue glycans on all-quality experimental data is 42.1% (n = 131 clusters), which is slightly lower than the success rate for single-residue glycans on all-quality experimental data of 46.1% (n = 167). The modified residues dataset is filtered similarly to our other polymer test sets: it contains only modified residues in polymer chains with low homology to the training set (Methods). See Extended Data Table 1 for detailed results, and Extended Data Fig. 6 for examples of predicted protein, DNA and RNA structures with covalent modifications, including analysis of the impact of phosphorylation on predictions.
    共有結合による修飾（結合リガンド、グリコシル化、修飾されたタンパク質残基や核酸塩基）も、AF3によって正確に事前予測される（図1c（中央右））。修飾には、あらゆる高分子残基（タンパク質、RNA、DNA）が含まれる。精度は、予測に成功した割合（ポケットのr.m.s.d. < 2 Å）として報告する。PoseBustersと同様に、結合リガンドとグリコシル化のデータセットに品質フィルターを適用し、高品質な実験データ（RCSB structure valida-tionレポートによるranking_model_fit > 0.5、つまり中央値以上のモデル品質を持つX線構造）を持つリガンドのみを含める。PoseBustersセットと同様に、結合リガンドと糖鎖のデータセットもトレーニングデータセットとの相同性によるフィルタリングは行っていない。結合ポリマー鎖の相同性（ポリマーテンプレートの類似度<40を使用）に基づいてフィルタリングした結果、結合リガンドでは5クラスタ、グリコシル化では7クラスタしか得られなかった。RCSBの検証レポートでは多残基糖鎖に対するranking_model_fitの値が提供されていないため、ここでは多残基糖鎖を除外した。全ての質の実験データにおけるマルチ残基糖鎖のプレディクション成功率（ポケットr.m.s.d. < 2 Å）は42.1%（n = 131クラスタ）であり、全ての質の実験データにおけるシングル残基糖鎖の成功率46.1%（n = 167）よりわずかに低い。修飾残基データセットは、他のポリマーテストセットと同様にフィルタリングされている：トレーニングセットとの相同性が低いポリマー鎖の修飾残基のみが含まれている（Methods）。詳細な結果についてはExtended Data Table 1を、共有結合修飾を持つタンパク質、DNA、RNA構造の予測例（リン酸化が予測に与える影響の解析を含む）についてはExtended Data Fig.


    AF3は, AFMultimer2.3(..これまでの最新版?)と比べてタンパク質の構造予測の性能も向上している。DockQ>0.23の割合?が向上している(paired wilcoxon signed-rank test, p=1.8*10^-18とのこと)。(1c右)特に抗体とタンパク質の複合体構造の予測がとても向上している。
    評価指標が通常とは異なるらしい。詳細は5aとのこと。
    (S7a) AF2.3と同様に, MSA鎖が深いほど精度が良かった。
    AF3は, モデリング能力を拡張しつつも, タンパク質複合体の予測についてもAF-Multimer v2.3から改善している。
    タンパク質とタンパク質の複合体の予測は全体的に成功したもの(DockQ>0.23)の割合が増加し(対応付きWilcoxonの符号付き順位検定, P=1.8x10^-18), 特に抗体とタンパク質の相互作用予測が際立って向上した(1c右, 対応有Wilcoxonの符号付検定, P=6.5x10^-5)。
While expanding in modelling abilities, AF3 has also improved in protein complex accuracy relative to AlphaFold-Multimer (v.2.3)7,8. Generally, protein–protein prediction success (DockQ > 0.23)40 has increased (paired Wilcoxon signed-rank test, P = 1.8 × 10−18), with antibody–protein interaction prediction in particular showing a marked improvement (Fig. 1c (right); paired Wilcoxon signed-rank test, P = 6.5 × 10−5, predictions top-ranked from 1,000 rather than the typical 5 seeds; further details are provided in Fig. 5a). Protein monomer LDDT improvement is also significant (paired Wilcoxon signed-rank test, P = 1.7 × 10−34). AF3 has a very similar dependence on MSA depth to AlphaFold-Multimer v.2.3; proteins with shallow MSAs are predicted with lower accuracy (a comparison of the dependence of single-chain LDDT on MSA depth is shown in Extended Data Fig. 7a).
    AF3はモデル化能力を拡張する一方で、AlphaFold-Multimer（v.2.3）7,8と比較してタンパク質複合体の精度も向上している。一般に、タンパク質間相互作用予測の成功率（DockQ > 0.23）40 は向上しており（paired Wilcoxon signed-rank test, P = 1.8 × 10-18）、特に抗体-タンパク質間相互作用予測は顕著な改善を見せています（図1c（右）；paired Wilcoxon signed-rank test, P = 6.5 × 10-5、予測値のトップランクは一般的な5種ではなく1,000種から；詳細は図5aに記載）。タンパク質モノマーLDDTの改善も有意である（対のウィルコクソンの符号順位検定、P = 1.7 × 10-34）。AF3はAlphaFold-Multimer v.2.3と非常によく似たMSAの深さ依存性を示し、MSAが浅いタンパク質はより低い精度で予測されます（MSAの深さに対する一本鎖LDDTの依存性の比較はExtended Data Fig.7aに示されています）。

# Predicted confidences track accuracy
    E8, 4a, 4b-e, E5c,d

    (S8)相同性フィルタリングを行わないデータセットについて評価した。
    トップランクの予測のみ評価しているらしい(...どういうこと?)

    AF2同様, AF3の信頼度予測もよく校正されている。
    信頼度の評価は, 最近のPDBの評価用データについて, 学習データとの類似性によるフィルタリングなしのものについて行っている。
    リガンドについては上に述べたような高精度の実験結果に限定しており, 通常の共有結合していないリガンドに限定している。
    結合しているリガンドやその他のインターフェースについての評価は図E8を参照。
    全ての統計量はcluster-weighted(?, method参照とのこと)で, top-rankの予測のみ考慮している(rankingの詳細は方法5.9.3を参照)。
As with AF2, AF3 confidence measures are well calibrated with accuracy. Our confidence analysis is performed on the recent PDB evaluation set, with no homology filtering and including peptides. The ligands category is filtered to high-quality experimental structures as described above, and considers standard non-bonded ligands only. See Extended Data Fig. 8 for a similar assessment on bonded ligand and other interfaces. All statistics are cluster-weighted (Methods) and consider the top-ranked prediction only (ranking details are provided in Supplementary Methods 5.9.3).
    AF2と同様に、AF3の信頼度測定は精度よく較正されている。我々の信頼度解析は、相同性フィルタリングを行わず、ペプチドを含む最近のPDB評価セットに対して行われた。リガンドカテゴリは、上記のように高品質な実験的構造にフィルタリングされ、標準的な非結合リガンドのみを考慮する。結合リガンドとその他の相互面に関する同様の評価については、Extended Data Fig. すべての統計はクラスタ重み付けされ（Methods）、トップランクの予測のみを考慮する（ランキングの詳細はSupplementary Methods 5.9.3に記載）。
    
    図4aの上側では, chain pair interface-predicted TM(ipTM)スコア(SM5.9.1を参照)と境界面の精度の指標を比較している: タンパク質間相互作用についてはDockQ, タンパク質と核酸の境界面についてはiLDDT, タンパク質とリガンドの境界面についてはポケットを揃えた時の(リガンドの?)RMSDがthreshold(2A?)以下の者の割合を比較した。
    図4aの下段では, タンパク質, ヌクレオチド, リガンドについての平均のpLDDTを, bespoke LDDT_to_polymer指標(指標の詳細はMethodsを参照)に対してプロットしている。
In Fig. 4a (top row), we plot the chain pair interface-predicted TM (ipTM) score41 (Supplementary Methods 5.9.1) against interface accuracy measures: protein–protein DockQ, protein–nucleic interface LDDT (iLDDT) and protein–ligand success, with success defined as the percentage of examples under thresholded pocket-aligned r.m.s.d. values. In Fig. 4a (bottom row), we plot the average pLDDT per protein, nucleotide or ligand entity against our bespoke LDDT_to_polymer metric (metrics details are provided in the Methods), which is closely related to the training target of the pLDDT predictor.
    図4a（上段）では、鎖ペア界面予測TM（ipTM）スコア41（補足メソッド5.9.1）を、界面精度指標であるタンパク質-タンパク質DockQ、タンパク質-核界面LDDT（iLDDT）、タンパク質-リガンド成功に対してプロットしています。図4a（下段）では、タンパク質、ヌクレオチド、またはリガンド・エンティティーごとの平均pLDDTを、pLDDT予測器のトレーニングターゲットと密接に関連する、特注のLDDT_to_polymerメトリック（メトリクスの詳細はMethodsに記載）に対してプロットしています。

    図4b~eでは, 7T82の予測のみを取り上げ, 原子ごとのpLDDTを4段階に色分けして表示している(b)。図4cでは同じ7T82の予測構造を鎖ごとに色分けしており(この色はpLDDTを表すわけではなく, 単に鎖の識別のために色分けしているということだと思う。色違うので。), 4dでは各鎖の組についてのDockQスコアを表す。4eでは各残基ペアについての予測された距離の誤差を表す。4d, 4eでは見やすさのため鎖の色分けをつけている。CとD, AとFはDockQスコアが高くなっており, その部分はpLDDTが高く予測されているが, AとC, AとDについてはDockQのスコアが低く, pLDDTも低くなっている。
In Fig. 4b–e, we highlight a single example prediction of 7T82, in which per-atom pLDDT colouring identifies unconfident chain tails, somewhat confident interfaces and otherwise confident secondary structure. In Fig. 4c, the same prediction is coloured by chain, along with DockQ interface scores in Fig. 4d and per-chain colouring displayed on the axes for reference. We see from Fig. 4e that PAE confidence is high for pink–grey and blue–orange residue pairs for which DockQ > 0.7, and least confident about pink–orange and pink–blue residue pairs that have DockQ ≈ 0. A similar PAE analysis of an example with protein and nucleic acid chains is shown in Extended Data Fig. 5c,d.
    図4b-eでは、7T82の予測例をハイライトし、原子ごとのpLDDTカラーリングにより、確信のない鎖尾部、やや確信のある界面、それ以外は確信のある二次構造を識別しています。図4cでは、同じ予測を鎖ごとに色分けし、図4dではDockQインターフェースのスコアと鎖ごとの色分けを軸に表示しています。図4eから、PAEの確信度は、DockQ > 0.7であるピンク-灰色と青-橙色の残基ペアに対して高く、DockQ≈0であるピンク-橙色とピンク-青色の残基ペアに対して最も確信度が低いことがわかります。タンパク質鎖と核酸鎖を持つ例の同様のPAE分析は、拡張データ図5c,dに示されています。

# Model limitations
    5a
We note model limitations of AF3 with respect to stereochemistry, hallucinations, dynamics and accuracy for certain targets.
    我々は、立体化学、幻覚、ダイナミクス、特定のターゲットに対する精度に関するAF3のモデルの限界に注目している。


On stereochemistry, we note two main classes of violations. The first is that the model outputs do not always respect chirality (Fig. 5b), despite the model receiving reference structures with correct chirality as input features. To address this in the PoseBusters benchmark, we included a penalty for chirality violation in our ranking formula for model predictions. Despite this, we still observe a chirality violation rate of 4.4% in the benchmark. The second class of stereochemical violations is a tendency of the model to occasionally produce overlap- ping (clashing) atoms in the predictions. This sometimes manifests as extreme violations in homomers in which entire chains have been observed to overlap (Fig. 5e). Penalizing clashes during ranking (Sup- plementary Methods 5.9.3) reduces the occurrence of this failure mode but does not eliminate them. Almost all remaining clashes occur for protein–nucleic complexes with both greater than 100 nucleotides and greater than 2,000 residues in total.
    立体化学に関しては、2つの主な違反がある。1つ目は、正しいキラリティを持つ参照構造 を入力特徴としてモデルが受け取ったにもかかわらず、モ デル出力が必ずしもキラリティを尊重していないこ とである（図5b）。PoseBustersベンチマークでこの問題に対処するため、モデル予測のランキング式にキラリティ違反に対するペナルティを含めました。にもかかわらず、ベンチマークでは4.4%のキラリティ違反率が観測された。立体化学的違反の2つ目のクラスは、予測においてモデルが時折オーバーラップする（衝突する）原子を生成する傾向です。これは、鎖全体が重なり合うホモマーにおいて、極端な違反として現れることがあります（図5e）。ランク付けの際に衝突にペナルティを与える（補足方法5.9.3）ことで、この失敗モードの発生を減らすことはできますが、なくすことはできません。残りのほとんど全ての衝突は、100ヌクレオチド以上と2,000残基以上のタンパク質-核酸複合体で起こる。

We note that the switch from the non-generative AF2 model to the diffusion-based AF3 model introduces the challenge of spurious struc- tural order (hallucinations) in disordered regions (Fig. 5d and Extended Data Fig. 1). Although hallucinated regions are typically marked as very low confidence, they can lack the distinctive ribbon-like appearance that AF2 produces in disordered regions. To encourage ribbon-like predictions in AF3, we use distillation training from AF2 predictions, and we add a ranking term to encourage results with more solvent accessible surface area36.
    非再生的AF2モデルから拡散に基づくAF3モデルへの切り替えは、無秩序領域における偽の構造秩序（幻覚）という課題をもたらすことに注意されたい（図5dと拡張データ図1）。幻覚領域は通常、非常に信頼度が低いとマークされるが、AF2が無秩序領域で作り出すような、特徴的なリボンのような外観を持たないことがある。AF3でリボンのような予測を奨励するために、AF2の予測から蒸留トレーニングを使用し、より溶媒にアクセス可能な表面積を持つ結果を奨励するためにランキング項を追加した36。

A key limitation of protein structure prediction models is that they typically predict static structures as seen in the PDB, not the dynamical behaviour of biomolecular systems in solution. This limitation persists for AF3, in which multiple random seeds for either the diffusion head or the overall network do not produce an approximation of the solu- tion ensemble.
    タンパク質構造予測モデルの重要な限界は、一般的にPDBで見られるような静的構造を予測することであり、溶液中の生体分子系の動的挙動を予測することではない。この限界はAF3でも続いており、拡散ヘッドまたはネットワーク全体に対して複数のランダムシードを用いても、溶液アンサンブルの近似は得られない。

In some cases, the modelled conformational state may not be correct or comprehensive given the specified ligands and other inputs. For example, E3 ubiquitin ligases natively adopt an open conformation in an apo state and have been observed only in a closed state when bound to ligands, but AF3 exclusively predicts the closed state for both holo and apo systems42 (Fig. 5c). Many methods have been developed, particularly around MSA resampling, that assist in generating diversity from previous AlphaFold models43–45 and may also assist in multistate prediction with AF3.
    場合によっては、指定されたリガンドや他のインプットを考慮すると、モデル化されたコンフォメーション状態が正しくなかったり、包括的でなかったりすることがある。例えば、E3ユビキチンリガーゼはアポの状態ではオープンなコンフォメーションをとり、リガンドと結合した状態ではクローズドなコンフォメーションしか観測されないが、AF3はホロとアポの両方の系に対してクローズドなコンフォメーションを予測する42（図5c）。特にMSAリサンプリングを中心に、これまでのAlphaFoldモデルから多様性を生み出すのに役立つ多くの手法が開発されており43-45、AF3による多状態予測にも役立つ可能性がある。

Despite the large advance in modelling accuracy in AF3, there are still many targets for which accurate modelling can be challenging. To obtain the highest accuracy, it may be necessary to generate a large number of predictions and rank them, which incurs an extra computational cost. A class of targets in which we observe this effect strongly is antibody–antigen complexes, similar to other recent work46. Figure 5a shows that, for AF3, top-ranked predictions keep improving with more model seeds, even at as many as 1,000 (Wilcoxon signed-rank test between 5 and 1,000 seeds, P = 2.0 × 10−5 for percentage correct and P = 0.009 for percentage very high accuracy; ranking by protein– protein interface ipTM). This large improvement with many seeds is not observed in general for other classes of molecules (Extended Data Fig. 7b). Using only one diffusion sample per model seed for the AF3 predictions rather than five (not illustrated) does not change the results significantly, indicating that running more model seeds is necessary for antibody score improvements, rather than just more diffusion samples
    AF3ではモデリング精度が大幅に向上したが、正確なモデリングが困難なターゲットもまだ多く存在する。最高の精度を得るためには、多数の予測値を生成し、それらをランク付けする必要があるかもしれないが、これには余分な計算コストがかかる。この効果が強く観察されるターゲットのクラスは、抗体-抗原複合体であり、他の最近の研究と同様である46。図5aは、AF3において、上位にランクされた予測は、モデルシードが1,000個と多くなるにつれて、改善され続けていることを示している（5個と1,000個のシード間のWilcoxon符号順位検定、正答率のP = 2.0 × 10-5、非常に高い精度の割合のP = 0.009、タンパク質-タンパク質界面ipTMによるランク付け）。多くのシードによるこの大きな改善は、他のクラスの分子では一般的に観察されない（Extended Data Fig.7b）。AF3の予測では、モデルシード1つにつき拡散サンプルを5つではなく1つだけ使用しても（図示せず）、結果は大きく変わりません。これは、抗体スコアの改善には、拡散サンプルを増やすよりも、モデルシードを増やすことが必要であることを示しています。

# Discussion
The core challenge of molecular biology is to understand and ultimately regulate the complex atomic interactions of biological systems. The AF3 model takes a large step in this direction, demonstrating that it is pos- sible to accurately predict the structure of a wide range of biomolecular systems in a unified framework. Although there are still substantial challenges to achieve highly accurate predictions across all interaction types, we demonstrate that it is possible to build a deep-learning system that shows strong coverage and generalization for all of these interac- tions. We also demonstrate that the lack of cross-entity evolution- ary information is not a substantial blocker to progress in predicting these interactions and, moreover, substantial improvement in antibody results suggests AlphaFold-derived methods are able to model the chemistry and physics of classes of molecular interactions without dependence on MSAs. Finally, the large improvement in protein–ligand structure prediction shows that it is possible to handle the wide diver- sity of chemical space within a general deep-learning framework and without resorting to an artificial separation between protein structure prediction and ligand docking.
    分子生物学の中心的な課題は、生体システムの複雑な原子間相互作用を理解し、最終的に制御することである。AF3モデルはこの方向へ大きく一歩を踏み出し、統一された枠組みで幅広い生体分子系の構造を正確に予測することが可能であることを実証した。すべての相互作用タイプにおいて高精度な予測を達成するためには、まだ大きな課題が残っているが、これらの相互作用のすべてに対して強力なカバレッジと汎化を示すディープラーニングシステムを構築することが可能であることを実証した。さらに、抗体の結果が大幅に改善されたことは、AlphaFold由来の手法が、MSAに依存することなく、分子間相互作用のクラスの化学と物理をモデル化できることを示唆している。最後に、タンパク質-リガンド構造予測における大幅な改善は、一般的なディープラーニングの枠組みの中で、タンパク質構造予測とリガンドドッキングの間の人為的な分離に頼ることなく、多様な化学空間を扱うことが可能であることを示している。

The development of bottom-up modelling of cellular components is a key step in unravelling the complexity of molecular regulation within the cell, and the performance of AF3 shows that developing the right deep-learning frameworks can massively reduce the amount of data required to obtain biologically relevant performance on these tasks and amplify the impact of the data already collected. We expect that structural modelling will continue to improve not only due to advances in deep learning but also because continuing methodologi- cal advances in experimental structure determination, such as the substantial improvements in cryo-electron microscopy and tomogra- phy, will provide a wealth of new training data to further the improve the generalization ability of such models. The parallel developments of experimental and computational methods promise to propel us further into an era of structurally informed biological understanding and therapeutic development.
    細胞成分のボトムアップモデリングの開発は、細胞内の複雑な分子制御を解明する上で重要なステップであり、AF3の性能は、適切なディープラーニングフレームワークを開発することで、これらのタスクで生物学的に適切な性能を得るために必要なデータ量を大幅に削減し、既に収集されたデータのインパクトを増幅できることを示している。構造モデリングは、ディープラーニングの進歩だけでなく、クライオ電子顕微鏡やトモグラフィの大幅な改善など、実験的構造決定における方法論の継続的な進歩が、このようなモデルの汎化能力をさらに向上させるための豊富な新しい学習データを提供するため、今後も改善され続けるものと期待される。実験的手法と計算機的手法の並行的な発展により、構造情報に基づいた生物学的理解と治療法開発の時代へのさらなる推進が期待される。

# Online content
Any methods, additional references, Nature Portfolio reporting summa- ries, source data, extended data, supplementary information, acknowl- edgements, peer review information; details of author contributions and competing interests; and statements of data and code availability are available at https://doi.org/10.1038/s41586-024-07487-w.
    方法、追加参考文献、Nature Portfolio報告サマリー、ソースデータ、拡張データ、補足情報、謝辞、査読情報、著者の貢献と競合利益の詳細、およびデータとコードの利用可能性に関する声明は、https://doi.org/10.1038/s41586-024-07487-w。


# Method

## Full algorithm details

## Training regime

## Inference regime

## Metrics


Evaluation compares a predicted structure to the corresponding ground-truth structure. If the complex contains multiple identical entities, assignment of the predicted units to the ground-truth units is found by maximizing LDDT. Assignment in local symmetry groups of atoms in ligands is solved by exhaustive search over the first 1,000 per-residue symmetries as given by RDKit.
    評価では、予測された構造と対応する基底真理構造を比較する。 複合体が複数の同じ実体を含む場合、予測されたユニットの基底真実ユニットへの割り当ては、LDDTを最大化することによって求められます。 配位子中の原子の局所的な対称性グループにおける割り当ては、RDKitが与える最初の1,000個の残基ごとの対称性を網羅的に探索することで解決されます。

    予測の品質は, DockQ, LDDT, またはポケットを揃えた時のRMSDによって評価する。
    核酸とタンパク質の境界面については, 境界面上の異なる鎖間の原子の距離から計算されるiLDDTを計算する。
    DockQとiLDDTは強く相関しているので, DockQの標準的なthresholdを同値なiLDDTの値に変換できる。
    核酸はスケールが大きいので, 鎖間, および境界面のLDDTは通常の15Åより大きい30Å以下の原子ペアについて計算される。
    信頼度がcalibrationされているかの評価には, 各原子と全ての中心原子を結ぶ(15Å又は30Å以下の)ペアについて計算したbespoke LDDTを用いた。
    これは, 信頼度評価がどのように学習されているかと関係している。
We measure the quality of the predictions with DockQ, LDDT or pocket-aligned r.m.s.d. For nucleic–protein interfaces, we measure interface accuracy through iLDDT, which is calculated from distances between atoms across different chains in the interface. DockQ and iLDDT are highly correlated (Extended Data Fig. 9), so the standard cut-offs for DockQ can be translated to equivalent iLDDT cut-offs. Nucleic acid LDDTs (intrachains and interface) were calculated with an inclusion radius of 30 Å compared with the usual 15 Å used for proteins, owing to their larger scale. For confidence calibration assessment, we use a bespoke LDDT (LDDT_to_polymer) metric that considers differences from each atom of a given entity to any Cα or C1′ polymer atom within its inclusion radius. This is closely related to how the confidence prediction is trained (Supplementary Methods 4.3.1).
    核-タンパク質界面については、界面の異なる鎖間の原子間距離から計算されるiLDDTによって界面精度を測定する。 DockQとiLDDTは相関性が高いので（Extended Data Fig. 核酸LDDT（鎖内および界面）は、スケールが大きいため、タンパク質で通常使用される15Åと比較して、30Åの包含半径で計算された。 信頼度較正の評価には、与えられた実体の各原子から包含半径内の任意のCαまたはC1′ポリマー原子までの差を考慮する特注のLDDT（LDDT_to_polymer）メトリックを使用する。 これは信頼度予測の学習方法と密接に関連している（補足手法4.3.1）。
    ... リガンドのLDDT to polymerはどうやって計算するのか? 

    pocket-aligned RMSDは以下のように計算される: ポケットは, リガンドのいずれかの重原子から10Å以内にある, リガンドや修飾残基にとって主要な(=一番メインで結合している?)ポリマーの全ての重原子であり, タンパク質についてはさらに主鎖の原子に限定する。
    主要な鎖は, データごとに異なる方法で定義される。PoseBustersについては, 10Å以内の重原子を最も含む鎖である。ポリマーに結合したリガンドについては, それが結合しているポリマーである。修飾された残基については, その残基がある鎖(からその残基そのものを除いたもの)である。
    ポケットは, 正解構造となるべく誤差(RMSD?)が小さくなるように配置され, その後リガンドの全ての重原子についてRMSDを計算する。
Pocket-aligned r.m.s.d. is computed as follows: the pocket is defined as all heavy atoms within 10 Å of any heavy atom of the ligand, restricted to the primary polymer chain for the ligand or modified residue being scored, and further restricted to only backbone atoms for proteins. The primary polymer chain is defined variously: for PoseBusters, it is the protein chain with the most atoms within 10 Å of the ligand; for bonded ligand scores, it is the bonded polymer chain; and for modified residues, it is the chain in which the residue is contained (minus that residue). The pocket is used to align the predicted structure to the ground-truth structure with least-squares rigid alignment and then the r.m.s.d. is computed on all heavy atoms of the ligand.
    ポケットはリガンドの重原子から10Å以内のすべての重原子と定義され、リガンドまたは修飾残基のスコアでは一次ポリマー鎖に限定され、タンパク質の場合はさらに骨格原子に限定される。 一次ポリマー鎖の定義は様々で、PoseBustersの場合はリガンドから10Å以内に最も多くの原子を持つタンパク質鎖、結合リガンドスコアの場合は結合ポリマー鎖、修飾残基の場合はその残基が含まれる鎖（その残基を除いたもの）である。 ポケットは、最小二乗法によるリジッドアライメントで、予測された構造をグランドトゥルース構造にアライメントするために使用され、次にリガンドのすべての重原子についてr.m.s.d.が計算されます。












# SI 
## 1 Notation
以下で使う記号はAF2と大体同じだが, 読者に便利なようここでまとめておく。

トークンの数は$N_token$(学習中はcropされる)。テンプレートの数は$N_templ$, MSAの行数を$N_msa$である。具体的な値はdata pipeline(2章), 学習の詳細(5章)にある。
モデルについては, pairformerのようなスタック中のブロックの数を$N_block$(3.6章), recycling iterationの数を$N_cycle$とする。
Algorigthmsでは, 以下の慣習に従って構造の詳細を示す。単語の始まりを大文字にした演算子名は, 学習されるパラメータを含んでいるものについて使う。例えばLinear, LinearNoBiasなど。Linear演算子から複数の出力があるときは, それぞれに対して学習可能なパラメータがあることを示す。また, LinearNoBias_aなど添え字があるときは, 複数のパラメータがあり, 添え字がどのパラメータを使うかを示している(Algorithm 31で使っている)。
LayerNormはチャネルごとのgain(って何?), bias付きの, チャネル方向へのlayer normalizationを示す。
ランダムなaugmentatoinなど, ランダムな演算子についても大文字で始まる名前を使う。
sigmoid, softmax, stopgradなど, パラメータのない関数については小文字の実の名前を使う。
$\odot$は要素ごとの積, $\otimes$は外積, $\oplus$は外和(?, outer sum), $\bm{a}^T\bm{b}$は内積を表す。添え字$i,j,k$は常にトークン次元上を走り, $l,m$はflat atom dimension(..?), s,tは配列の次元(MSA配列や拡散の時間方向), $h$はattention headの次元上を走る。チャネル方向の次元は明示的には書かず, チャネル方向のベクトルは太字で書く。このようなベクトルの組みは$\{\bm{z}_i,j\}$のように表す。
全ての原子構造は平坦な(=1次元の?)原子リスト$\{\vec{x}_l\}$で表される。(lは原子のindex)。
トークンと対応する原子は, $i(l)\in\mathbb{N}$($l$番目の原子が, $i$番目のトークンに属することを表す)と, token_atom_idx(l)($l$番目の原子が, 自分が属するトークンの中で何番目か)で表す。

- outer sum: 
```
>>> np.subtract.outer([6, 5, 4], [3, 2, 1])
array([[3, 4, 5],
       [2, 3, 4],
       [1, 2, 3]])
```

## 2 Datapileline

### 2.1 Parsing
mmCIFを入力として受け取る。
いくつかのメタデータも取得する。
後のコードの簡単化のため, いくつかの前処理を行う。
  原子座標にいくつか候補がある場合, 最も大きな割合(?, occupancy)を占めるものにする。
  MSE(セレノメチオニン)はMET(メチオニン)に変換する
  水分子を除去する
  アルギニンの原子の名前を修正
    常にNH1がNH2よりCDに近くなるようにする
    The first bioassembly is then expanded, to encourage the model to predict biologically relevant complexes
推論時には, 全ての原子座標が0のダミーmmCIFファイルを入力とする。

### 2.2 Genetic search
表1にある5つのデータベースから, それぞれ特定の検索プロトコルを使ってMSAを探す。
見つからない場合はquery配列1つを返す。
学習時は, MSAの数をk=Uniform[1,n]個に限定する。

### 2.3 MSA processing
最大16384のMSAを作る。最初の行がquery。
詳細は不明

### 2.4 Template search
タンパク質について, 類似した構造を検索するのか?
UniRef90のMSAから検索する?

### 2.5 training data

### 2.6 tokenization
表13にある通常のアミノ酸・核酸はそれを1つのトークンとしてあらわす。
それ以外のアミノ酸・核酸やリガンドは原子単位でトークン化
アミノ酸・核酸については, Calpha/C1原子を中心原子として指定(原子単位のトークンはその原子が中心)。

### 2.7 cropping
配列の継続を重視するか, 空間的な連続性を重視するかをデータセット・学習段階などによって変えた。

### 2.8 Featurisation and model inputs
モデルに入力される情報は:
1. トークン情報: 種類, chain id, is_protein
2. reference features: リガンドはRDKitのETKDGで作ったが, エラーの場合は別のを使ったので, どれを使ったかなど
3. MSA情報
4. template情報
5. 結合情報:
    リガンドの結合など

## 3 Model architecture
モデル構造は大まかにはAF2に基づいているが, より幅広い分子を予測するため, またタンパク質構造の予測精度向上のため, いくつかの変更を加えている。

モデルは条件付き生成モデルだが, 条件の生成の所に多くの計算時間を使っている。

条件生成がAF2のtrunkに似ている。
全体のアルゴリズムはAlgorithm1

embeddingにおいて, 全atomへのattentionをかけた。
    atomのみ?残基はかけていない?

### 3.3 MSA Module
pair-weighted averagingとは, 行方向のattentionだが, attention weightをquery, keyから計算するのでなくpair representationからprojectしたものをそのまま使うというもの。
なるべくこの後で使うペア表現が多くの情報を持ってほしいということで, MSAのrow間の相互作用は直接行わず, ペア表現を介して行うようにした。

### 3.4 triangle update
多分AF2と同じなので省略

### 3.5 Template embedding

### 3.6 pairformer stack
まあ図に書いてある通りなので省略

### 3.7 

## 4.3 Model confidence prediction
モデルは,
    原子ごとの信頼度
    LDDTの予測値(pLDDT)
    pairwise atom-atom aligned error(PAE)
    pairwise atom-atom distance confidence
    predicted distance error(PDE)
5個あるんですけど。
信頼度の学習はPDBの学習データのうち, 解像度が0.1~4のものに対してのみ行われ, 蒸留データなどに対しては学習しなかった。
以下に信頼度予測のheadとロス関数の詳細を述べる。

### 4.3.1 Predicted local distance difference test (pLDDT)
各原子についてのLDDTを予測する。予測するLDDTは通常と異なり, 全てタンパク質または核酸との距離のLDDTである(つまり, 例えばリガンド原子のLDDTの場合, リガンド間の距離の予測は含まれない)。  
原子$l$のLDDTは, 
$$
LDDT_l = \sum_{m\in R}\frac{1}{4} \sum_{c=0.5,1,2,4} \hat{d}_{lm}<c
$$
で表される。ここで,  
　$R$は原子$l$から一定距離(核酸なら30Å, タンパク質なら15Å)以下の原子の集合
$$
    R = \{m| mはタンパク質の原子かつ, d_{lm}<15Å\}\cup\{m|mは核酸原子かつ, d_{lm}<30Å\}
$$
　である。  
　$\hat{d}$は, 荒いstepで生成された構造における原子$l$と$m$の距離。

予測は, confidence head(31を参照)のembedding(各トークンに対してある)からprojectされる。トークン$i$のembedding$s_i$は, $[N_{max_atom_per_token}, 50]$次元の値$p_i$にprojectされ, これにsoftmaxをかけたものが, トークンに対応する各原子についての$LDDT_l$を, $[0,1]$を50個に分けたbinについて分布を予測するものとなる。ロスは,
$$
    L = -\frac{1}{N_{atom}}\sum_{l}\sum_{b=1}^{50}
$$
原子ごとのLDDTの予測値(pLDDT)は,予測されたbinごとの分布に対して平均を取ることで得られる。

### 4.3.2 predicted aligned error
原子のペアについての信頼度を得ることは, 境界面の信頼度や特定の原子間の相互作用の信頼度を得る上で重要である。
このため, 私たちはAF2に従い, pairwise element error, あるトークンについてフレームを揃えた時のもう1つのトークンのエラーを予測した。

PAEのターゲットの説明があったがよくわからん。まあ「あるトークンについてフレームを揃えた時のもう1つのトークンのエラー」ということでいいだろう。

pLDDTと同じように, 計算したエラーを0A~32Aで0.5A刻みでbinningしたあと, 各binに存在する確率分布を予測する。
予測の値としては平均値を使う。
この予測値をつかって, pTM, ipTMを予測した。
ipTMは, pTMのchain間の残基ペアのみを考慮したものである。
詳細はAF2, AF-Multimerを参照とのこと。

### 4.3.3 predicted distance error
PAEに加え, 原子間距離の誤差も直接予測する。
同じく, 0~32Aまでの64binの確率分布を予測する。


### 4.3.4 Experimentally resolved prediction
各原子の位置がどれくらい実験的に明らかになっているかも予測する。
    ... どこで使っているのか。



# その他サーベイ


### LDDT
https://pmc.ncbi.nlm.nih.gov/articles/PMC3799472/#sec2
に詳しい説明があった。
1. 正解の構造について, 距離がthreshold$R_0$以下で同じ残基に属さない原子ペアを全て抽出
2. それらのうち, 予測との距離の差が一定のthreshold以下のものを正解とする
    原子ペアのどちらかの原子が予測構造で欠けていたら不正解とする。
3. threshold(1.の?2.の?)を0.5A, 1A, 2A, 4Aにした時の正解したペアの平均値がLDDT
    AF3論文の4.3.1によると, 多分2.のthreshold

### TM score
「TM score」
https://www.bi.a.u-tokyo.ac.jp/~shimizu/str4.pdf
    タンパク質の各残基ペアの距離の和みたいな値だが, それだと距離が大きいものの影響が大きくなってしまうので, それを修正した値。
    (0, 1]の値をとり, 0.17以下はランダム, 0.5以上だと大体同じ, 1だと完全に一致

ipTM
chain pLDDT

