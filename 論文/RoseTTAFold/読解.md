https://www.science.org/doi/10.1126/science.abj8754

Accurate prediction of protein structures and interactions using a three-track neural network

https://www.biospace.info/blog/2023/07/03/rosettafold2/
にAF2とRFの違いがまとめられていた。
    RFの基本ブロックに3D構造トラックを含む
    biaxial attention (RF) vs triangle attention (AF2)
    SE3-equivariant transformer (RF) vs Invariant Point Attention (IPA) (AF2)
    8+4 2-track/3-track layers (RF) vs 4+48 full-msa/clustered-msa evoformer layers (AF2)

# editor's abstract
    CASP14ではAlphaFold2が高い性能を示した。本論文ではDeepMindのアーキテクチャをさらに探索し, 近い精度を達成した。
        ... AlpahFoldを元にしているのか, AlphaFold2を元にしているのか?
In 1972, Anfinsen won a Nobel prize for demonstrating a connection between a protein’s amino acid sequence and its three-dimensional structure. Since 1994, scientists have competed in the biannual Critical Assessment of Structure Prediction (CASP) protein-folding challenge. Deep learning methods took center stage at CASP14, with DeepMind’s Alphafold2 achieving remarkable accuracy. Baek et al. explored network architectures based on the DeepMind framework. They used a three-track network to process sequence, distance, and coordinate information simultaneously and achieved accuracies approaching those of DeepMind. The method, RoseTTA fold, can solve challenging x-ray crystallography and cryo–electron microscopy modeling problems and generate accurate models of protein-protein complexes.
    1972年、アンフィンセンはタンパク質のアミノ酸配列とその立体構造との関連性を証明したことでノーベル賞を受賞した。 1994年以来、科学者たちは年2回開催されるタンパク質折り畳みチャレンジ「構造予測クリティカルアセスメント（CASP）」で競い合ってきた。 CASP14では、ディープラーニング手法が主役となり、DeepMindのAlphafold2が目覚ましい精度を達成した。 Baekらは、DeepMindのフレームワークに基づくネットワーク・アーキテクチャを探求した。 彼らは、配列、距離、座標情報を同時に処理する3トラックネットワークを使用し、DeepMindに迫る精度を達成した。 この手法「RoseTTA fold」は、X線結晶構造解析や低温電子顕微鏡によるモデリングの難題を解決し、タンパク質-タンパク質複合体の正確なモデルを生成することができる。

# Abstract
    DeepMindはCASP14で高い性能を示した。私たちは関連するアイデアを探索し, それに迫る精度を達成した。
DeepMind presented notably accurate predictions at the recent 14th Critical Assessment of Structure Prediction (CASP14) conference. We explored network architectures that incorporate related ideas and obtained the best performance with a three-track network in which information at the one-dimensional (1D) sequence level, the 2D distance map level, and the 3D coordinate level is successively transformed and integrated. The three-track network produces structure predictions with accuracies approaching those of DeepMind in CASP14, enables the rapid solution of challenging x-ray crystallography and cryo–electron microscopy structure modeling problems, and provides insights into the functions of proteins of currently unknown structure. The network also enables rapid generation of accurate protein-protein complex models from sequence information alone, short-circuiting traditional approaches that require modeling of individual subunits followed by docking. We make the method available to the scientific community to speed biological research.
    DeepMindは、最近開催された第14回Critical Assessment of Structure Prediction (CASP14)カンファレンスで、際立って正確な予測を発表した。 我々は、関連するアイデアを取り入れたネットワーク・アーキテクチャを検討し、1次元（1D）配列レベル、2次元距離マップレベル、3次元座標レベルの情報を連続的に変換・統合する3トラック・ネットワークで最高の性能を得た。 この3トラックネットワークは、CASP14のDeepMindに迫る精度で構造予測を行い、困難なX線結晶構造解析や低温電子顕微鏡構造モデリングの問題を迅速に解決することを可能にし、現在構造未知のタンパク質の機能に関する洞察を提供する。 また、このネットワークは、配列情報のみから正確なタンパク質-タンパク質複合体モデルを迅速に生成することを可能にし、個々のサブユニットのモデリングの後にドッキングを必要とする従来のアプローチを短絡化する。 我々は、生物学的研究を加速するために、この手法を科学コミュニティに提供している。

# main
    アミノ酸配列からの構造予測は長年の課題であり, 毎年CASPが行われてきた。AlphaFold2が高い性能を示したことで, その詳細に興味がもたれ, DeepLearning企業以外でも同様の成績が可能かどうか注目された。
    AF2の特徴的な点は以下のようなものである。
        1. MSAから計算した数値などでなく, MSAを直接入力としていること。
        2. 2次元の畳み込み(...GNN?)をattention機構にすることで, 遠く離れた残基間の相互作用を計算できるようにした。
        3. 1次元レベルの情報と2次元レベルの情報を繰り返し更新・情報交換する2つのトラックからなる構造の採用
        4. 2トラックからの情報から(既存研究のような原子間距離ではなく)原子座標を直接生成するSE(3)-equivariantなTransformerの採用(...IPAやstructure moduleのこと?)
        5. 配列から構造まで全体のモデルパラメータをback-propagationにより更新するend-to-endモデルの利用
    
The prediction of protein structure from amino acid sequence information alone has been a long-standing challenge. The biannual Critical Assessment of Structure Prediction (CASP) meetings have demonstrated that deep-learning methods such as AlphaFold (1, 2) and trRosetta (3), which extract information from the large database of known protein structures in the Protein Data Bank (PDB), outperform more traditional approaches that explicitly model the folding process. The outstanding performance of DeepMind’s AlphaFold2 in the recent 14th CASP (CASP14) meeting (https://predictioncenter.org/casp14/zscores_final.cgi) left the scientific community eager to learn details beyond the overall framework that was presented and raised the question of whether such accuracy could be achieved outside of a world-leading deep-learning company. As described at the CASP14 conference, the AlphaFold2 methodological advances included (i) starting from multiple sequence alignments (MSAs) rather than from more-processed features such as inverse covariance matrices derived from MSAs, (ii) replacement of two-dimensional (2D) convolution with an attention mechanism that better represents interactions between residues distant along the sequence, (iii) use of a two-track network architecture in which information at the 1D sequence level and the 2D distance map level is iteratively transformed and passed back and forth, (iv) use of an SE(3)-equivariant Transformer network to directly refine atomic coordinates (rather than 2D distance maps as in previous approaches) generated from the two-track network, and (v) end-to-end learning in which all network parameters are optimized by backpropagation from the final generated 3D coordinates through all network layers back to the input sequence.
    アミノ酸配列情報のみからタンパク質の構造を予測することは、長年の課題であった。 年2回開催されるCritical Assessment of Structure Prediction (CASP)ミーティングでは、Protein Data Bank (PDB)にある既知のタンパク質構造の大規模データベースから情報を抽出するAlphaFold (1, 2)やtrRosetta (3)などのディープラーニング手法が、フォールディングプロセスを明示的にモデル化したより伝統的なアプローチを凌駕することが実証されている。 先日の第14回CASP（CASP14）会議（https://predictioncenter.org/casp14/zscores_final.cgi）におけるDeepMindのAlphaFold2の卓越した性能は、科学コミュニティに、発表された全体的な枠組みを超えた詳細を知りたいと思わせ、世界をリードするディープラーニング企業以外でもこのような精度を達成できるのかという疑問を投げかけた。 CASP14会議で説明されたように、AlphaFold2の方法論的進歩には、（i）MSAから得られる逆共分散行列のような、より処理された特徴からではなく、マルチプル配列アラインメント（MSA）から開始すること、（ii）2次元（2D）畳み込みを、配列に沿って離れた残基間の相互作用をよりよく表現する注意メカニズムに置き換えること、（iii）2次元（2D）畳み込みを、配列に沿って離れた残基間の相互作用をよりよく表現する注意メカニズムに置き換えること、などが含まれる、 (iii)1次元配列レベルの情報と2次元距離マップレベルの情報が繰り返し変換され、行き来する2トラックネットワークアーキテクチャの使用、(iv)2トラックネットワークから生成された原子座標（以前のアプローチのような2次元距離マップではなく）を直接洗練するためのSE(3)-equivariant Transformerネットワークの使用、(v)最終的に生成された3次元座標からすべてのネットワーク層を通して入力配列に戻るバックプロパゲーションにより、すべてのネットワークパラメータが最適化されるエンドツーエンド学習。

## Network architecture development
    私たちはAF2の結果に興味を持ち, 上記5つの特徴のうちいくつかを持つネットワーク構造について探索した。出版されている方法がないので, 私たちは表S1にまとめられているような様々な方法を試した。その結果, trRosettaを上回り, AF2に次ぐ精度を持つ2トラックネットワークの作成に成功した。<終了>
Intrigued by the DeepMind results, and with the goal of increasing protein structure prediction accuracy for structural biology research and advancing protein design (4), we explored network architectures that incorporate different combinations of these five properties. In the absence of a published method, we experimented with a wide variety of approaches for passing information between different parts of the networks, as summarized in the methods and table S1. We succeeded in producing a “two-track” network with information flowing in parallel along a 1D sequence alignment track and a 2D distance matrix track with considerably better performance than trRosetta (BAKER-ROSETTASERVER and BAKER in Fig. 1B), the next-best method after AlphaFold2 in CASP14 (https://predictioncenter.org/casp14/zscores_final.cgi).
    DeepMindの結果に興味をそそられ、構造生物学研究のためのタンパク質構造予測精度を高め、タンパク質設計を進歩させることを目標に(4)、我々はこれら5つの特性の様々な組み合わせを組み込んだネットワーク・アーキテクチャを探求した。 公表されている方法がないため、方法と表S1にまとめたように、ネットワークの異なる部分間で情報を受け渡すための様々なアプローチを実験した。 我々は、CASP14のAlphaFold2（https://predictioncenter.org/casp14/zscores_final.cgi）の次に優れた手法であるtrRosetta（図1BのBAKER-ROSETTASERVERとBAKER）よりもかなり優れた性能で、1次元配列アライメント・トラックと2次元距離行列トラックに沿って情報が並行して流れる「2トラック」ネットワークを作り出すことに成功した。

We reasoned that better performance could be achieved by extending to a third track operating in 3D coordinate space to provide a tighter connection between sequence, residue-residue distances and orientations, and atomic coordinates. We constructed architectures with the two levels of the two-track model augmented with a third parallel structure track operating on 3D backbone coordinates, as depicted in Fig. 1A (see methods and fig. S1 for details). In this architecture, information flows back and forth between the 1D amino acid sequence information, the 2D distance map, and the 3D coordinates, allowing the network to collectively reason about relationships within and between sequences, distances, and coordinates. By contrast, reasoning about 3D atomic coordinates in the two-track AlphaFold2 architecture happens after processing of the 1D and 2D information is complete (although end-to-end training does link parameters to some extent). Because of computer hardware memory limitations, we could not train models on large proteins directly because the three-track models have many millions of parameters; instead, we presented to the network many discontinuous crops of the input sequence consisting of two discontinuous sequence segments spanning a total of 260 residues. To generate final models, we combined and averaged the 1D features and 2D distance and orientation predictions produced for each of the crops and then used two approaches to generate final 3D structures. In the first, the predicted residue-residue distance and orientation distributions are fed into pyRosetta (5) to generate all-atom models. In the second, the averaged 1D and 2D features are fed into a final SE(3)-equivariant layer (6), and, after end-to-end training from amino acid sequence to 3D coordinates, backbone coordinates are generated directly by the network (see methods). We refer to these networks, which also generate per-residue accuracy predictions, as RoseTTAFold. The first has the advantages of requiring lower-memory graphics processing units (GPUs) at inference time [for proteins with more than 400 residues, 8 gigabytes (GB) rather than 24 GB] and of producing full side-chain models but requires central processing unit (CPU) time for the pyRosetta structure modeling step.
    私たちは、配列、残基-残基間の距離と配向、原子座標の間のより緊密なつながりを提供するために、3D座標空間で動作する3番目のトラックに拡張することによって、より優れた性能を達成できると推論した。 我々は、図1Aに示すように、2トラックモデルの2つのレベルに、3次元バックボーン座標上で動作する3番目の並列構造トラックを追加したアーキテクチャを構築した（詳細は方法と図S1を参照）。 このアーキテクチャでは、情報は1次元アミノ酸配列情報、2次元距離マップ、3次元座標の間を行き来し、ネットワークが配列内および配列間、距離、座標の関係をまとめて推論できる。 対照的に、2トラックAlphaFold2アーキテクチャにおける3D原子座標に関する推論は、1Dと2Dの情報の処理が完了した後に行われる（エンドツーエンドのトレーニングはある程度パラメータをリンクさせるが）。 その代わりに、260残基にわたる2つの不連続な配列セグメントからなる入力配列の多くの不連続な作物をネットワークに提示した。 最終的なモデルを生成するために、それぞれのクロップで生成された1次元の特徴量と2次元の距離と方向の予測値を組み合わせて平均化し、2つのアプローチで最終的な3次元構造を生成した。 1つ目は、予測された残基-残基の距離と配向分布をpyRosetta(5)に入力し、全原子モデルを生成します。 2つ目は、平均化された1次元と2次元の特徴が最後のSE(3)-equivariant層(6)に供給され、アミノ酸配列から3次元座標へのend-to-endトレーニングの後、バックボーン座標がネットワークによって直接生成される(methods参照)。 これらのネットワークは、残基ごとの精度予測も生成するため、RoseTTAFoldと呼んでいる。 RoseTTAFoldは、推論時に必要なGPU（400残基以上のタンパク質では、24GBではなく8ギガバイト）のメモリが少なくて済み、完全な側鎖モデルを生成できる利点がありますが、pyRosettaの構造モデリングステップでは中央演算処理装置（CPU）の時間が必要です。

The three-track models with attention operating at the 1D, 2D, and 3D levels and information flowing between the three levels were the best models we tested (Fig. 1B), clearly outperforming the top two server groups (Zhang-server and BAKER-ROSETTASERVER), BAKER human group (ranked second among all groups), and our two-track attention models on CASP14 targets. As in the case of AlphaFold2, the correlation between MSA depth and model accuracy is lower for RoseTTAFold than for trRosetta and other methods tested at CASP14 (fig. S2). The performance of the three-track model on the CASP14 targets was still not as good as AlphaFold2 (Fig. 1B). This could reflect hardware limitations that limited the size of the models we could explore, alternative architectures or loss formulations, or more intensive use of the network for inference. DeepMind reported using several GPUs for days to make individual predictions, whereas our predictions are made in a single pass through the network in the same manner that would be used for a server; after sequence and template search (~1.5 hours), the end-to-end version of RoseTTAFold requires ~10 min on an RTX2080 GPU to generate backbone coordinates for proteins with fewer than 400 residues, and the pyRosetta version requires 5 min for network calculations on a single RTX2080 GPU and an hour for all-atom structure generation with 15 CPU cores. Incomplete optimization due to computer memory limitations and neglect of side-chain information likely explain the poorer performance of the end-to-end version compared with the pyRosetta version (Fig. 1B; the latter incorporates side-chain information at the all-atom relaxation stage); because SE(3)-equivariant layers are used in the main body of the three-track model, the added gain from the final SE(3) layer is likely less than that in the AlphaFold2 case. We expect the end-to-end approach to ultimately be at least as accurate once the computer hardware limitations are overcome and side chains are incorporated.
    1次元、2次元、3次元の各レベルで注意力が働き、3つのレベル間で情報が流れる3トラックモデルは、テストした中で最も優れたモデルであり（図1B）、CASP14ターゲットにおいて、上位2つのサーバーグループ（Zhang-serverとBAKER-ROSETTASERVER）、BAKERヒトグループ（全グループ中2位）、および我々の2トラック注意力モデルを明らかに上回った。 AlphaFold2の場合と同様に、MSAの深さとモデルの精度の相関は、CASP14でテストされたtrRosettaや他の手法よりもRoseTTAFoldの方が低い（図S2）。 CASP14のターゲットに対する3トラックモデルの性能は、AlphaFold2ほどまだ良くなかった（図1B）。 これは、我々が探索できるモデルのサイズを制限するハードウェアの制限、代替アーキテクチャや損失定式化、または推論のためのネットワークのより集中的な使用を反映している可能性がある。 DeepMindは、個々の予測を行うために複数のGPUを数日間使用したと報告していますが、私たちの予測は、サーバーに使用されるのと同じ方法でネットワークを介して1回のパスで行われます。配列とテンプレート検索（〜1.5時間）の後、RoseTTAFoldのエンドツーエンドバージョンは、400残基未満のタンパク質のバックボーン座標を生成するためにRTX2080 GPUで〜10分必要であり、pyRosettaバージョンは、単一のRTX2080 GPUでネットワーク計算に5分、15 CPUコアで全原子構造生成に1時間必要です。 コンピュータのメモリ制限と側鎖情報の無視による不完全な最適化は、pyRosettaバージョンと比較したend-to-endバージョンのパフォーマンスの低さを説明すると思われます（図1B；後者は全原子緩和の段階で側鎖情報を取り込みます）；SE(3)-equivariant層が3トラックモデルの本体で使用されるため、最終的なSE(3)層からの付加利益はAlphaFold2の場合よりも少ないと思われます。 コンピュータのハードウェアの制約を克服し、サイドチェーンを組み込めば、最終的にはエンド・ツー・エンドのアプローチも少なくとも同程度の精度になると期待しています。

The improved performance of the three-track models over the two-track model with identical training sets, similar attention-based architectures for the 1D and 2D tracks, and similar operations in inference (prediction) mode suggests that simultaneously reasoning at the MSA, distance map, and 3D coordinate representations can more effectively extract sequence-structure relationships than reasoning over only MSA and distance map information. The relatively low computational cost makes it straightforward to incorporate the methods in a public server and predict structures for large sets of proteins, for example, all human G protein–coupled receptors (GPCRs), as described below.
    同一のトレーニングセット、1Dと2Dのトラックに対する同様の注意に基づくアーキテクチャ、推論（予測）モードにおける同様の操作で、2トラックモデルよりも3トラックモデルの性能が向上したことは、MSA、距離マップ、3D座標表現で同時に推論することで、MSAと距離マップ情報のみで推論するよりも、より効果的に配列と構造の関係を抽出できることを示唆している。 計算コストが比較的低いため、公開サーバーにこの手法を組み込むことが容易であり、例えば、以下に述べるように、全てのヒトGタンパク質共役受容体（GPCR）のような大規模なタンパク質セットの構造を予測することができる。

Blind structure prediction tests are needed to assess any new protein structure prediction method, but CASP is held only once every 2 years. Fortunately, the Continuous Automated Model Evaluation (CAMEO) experiment (7) tests structure prediction servers blindly on protein structures as they are submitted to the PDB. RoseTTAFold has been evaluated since 15 May 2021 on CAMEO; over the 69 medium and hard targets released during this time (15 May 2021 to 19 June 2021), it outperformed all other servers evaluated in the experiment, including Robetta (3), IntFold6-TS (8), BestSingleTemplate (9), and SWISS-MODEL (10) (Fig. 1C).
    新しいタンパク質構造予測手法の評価にはブラインド構造予測試験が必要だが、CASPは2年に1度しか開催されない。 幸い、Continuous Automated Model Evaluation (CAMEO)実験(7)では、PDBに投稿されたタンパク質構造に対してブラインドで構造予測サーバーをテストすることができる。 RoseTTAFoldは、2021年5月15日からCAMEOで評価されています。この間（2021年5月15日から2021年6月19日）に公開された69のミディアムターゲットとハードターゲットにおいて、Robetta(3)、IntFold6-TS(8)、BestSingleTemplate(9)、SWISS-MODEL(10)など、実験で評価された他のすべてのサーバーを上回りました（図1C）。

We experimented with approaches for further improving accuracy by more intensive use of the network during sampling. Because the network can take templates of known structures as input, we experimented with a further coupling of 3D structural information and 1D sequence information by iteratively feeding the predicted structures back into the network as templates and random subsampling from the MSAs to sample a broader range of models. These approaches generated ensembles that contained higher-accuracy models, but the accuracy predictor was not able to consistently identify models better than those generated by the rapid single-pass method (fig. S3). Nevertheless, we suspect that these approaches can improve model performance, and we are carrying out further investigations along these lines.
    我々は、サンプリング時にネットワークをより集中的に使用することにより、精度をさらに向上させるアプローチを実験した。 ネットワークは既知の構造のテンプレートを入力として取り込むことができるため、予測された構造をテンプレートとしてネットワークに繰り返し送り込み、MSAからランダムサブサンプリングを行うことで、3次元構造情報と1次元配列情報をさらに結合させ、より広範囲のモデルをサンプリングする実験を行った。 これらのアプローチは、より高精度なモデルを含むアンサンブルを生成したが、精度予測装置は、迅速なシングルパス法によって生成されたモデルよりも優れたモデルを一貫して同定することはできなかった（図S3）。 とはいえ、これらのアプローチはモデルの性能を向上させることができると思われ、我々はこの線に沿ってさらなる調査を行っている。


