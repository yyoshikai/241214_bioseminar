Efficient and accurate prediction of protein structure using RoseTTAFold2

https://www.biorxiv.org/content/10.1101/2023.05.24.542179v1.abstract

https://www.biospace.info/blog/2023/07/03/rosettafold2/
に読解がまとまっていた。
RF2ではこれらの両モデルの特徴を活かすことで、RFの改良を試みました。

RFからのRF2の改良点は以下のとおりとなります。
    ネットワークの反復は前処理ステップとして実行され、weightの更新を最終ラウンドの情報からのみ計算した
    タンパク質複合体情報を訓練データに追加した
    AF2予測構造を用いてモデルを蒸留した

-----------------
# Abstract
    AF2とRFは構造が大きく異なるにもかかわらず, どちらも高い精度でタンパク質構造を予測している。そこで私たちは, 両者の構造を組み合わせることでさらに高性能なモデルが得られないか調査した。その結果, 私たちはRFの3トラック構造をモデル全体に拡張し, AF2から
        1. Frame-aligned point error
        2. recycling during training: 初めに学習したモデルの予測結果で新しくモデルを学習するやつ?
        3. use of a distillation
    を取り入れた。また, 構造的な理論に対応するattentionを導入するというAF2の考え方を取り入れたが, AF2のtriangle-attentionではなくより効率的なstructure-biased attentionを導入した。
    開発したモデルは単量体についてはAF2, 複合体についてはAlphaFold2-multimerと同等の性能を示し, 大きなタンパク質や複合体に対しての計算効率が良くなった。
    この高い性能は, AF2の特徴であるinvariant point attentionとtriangle attentionなしで達成されており, 高精度な予測にこれらが必須ではないことを示している。
AlphaFold2 and RoseTTAFold predict protein structures with very high accuracy despite substantial architecture differences. We sought to develop an improved method combining features of both. The resulting method, RoseTTAFold2, extends the original three-track architecture of RoseTTAFold over the full network, incorporating the concepts of Frame-aligned point error, recycling during training, and the use of a distillation set from AlphaFold2. We also took from AlphaFold2 the idea of structurally coherent attention in updating pair features, but using a more computationally efficient structure-biased attention as opposed to triangle attention. The resulting model has the accuracy of AlphaFold2 on monomers, and AlphaFold2- multimer on complexes, with better computational scaling for large proteins and complexes. This excellent performance is achieved without hallmark features of AlphaFold2, invariant point attention and triangle attention, indicating that these are not essential for high accuracy prediction. Almost all recent work on protein structure prediction has re-used the basic AlphaFold2 architecture; our results show that excellent performance can be achieved with a broader class of models, opening the door for further exploration.
    AlphaFold2とRoseTTAFoldは、構造が大きく異なるにもかかわらず、非常に高い精度でタンパク質構造を予測する。我々は、両者の特徴を組み合わせた改良法を開発しようとした。その結果、RoseTTAFold2は、RoseTTAFoldのオリジナルの3トラックアーキテクチャーをネットワーク全体に拡張し、フレーム整列点誤差の概念、学習中のリサイクル、AlphaFold2からの蒸留セットの使用を取り入れた。また、AlphaFold2から、対の特徴を更新する際に構造的に一貫性のある注意を払うというアイデアを取り入れたが、三角形の注意とは対照的に、より計算効率の高い構造に偏った注意を使った。その結果、単量体に対してはAlphaFold2の精度を、複合体に対してはAlphaFold2- multimerの精度を持ち、大きなタンパク質や複合体に対してはより優れた計算スケーリングを実現した。この優れた性能は、AlphaFold2の特徴である不変点注意や三角形注意なしで達成されており、これらは高精度予測には必須ではないことを示している。タンパク質構造予測に関する最近の研究のほとんどは、基本的なAlphaFold2のアーキテクチャを再利用している。我々の結果は、より幅広いクラスのモデルで優れた性能を達成できることを示しており、さらなる探求の扉を開いている。

# Introduction
    RF1はAF2の構造が公開される前に発表され, どちらもタンパク質構造予測精度が高いが, AFの方が上である。
    RF1とAF2のモデル構造の違いとしては, 
        a. RFでは3次元構造を処理する3つ目のtrackを入れている
        b. ペア表現について, RFではbiaxial attentionを行っているのに対し, AF2ではtriangle multiplicationとtrialgle attentionを行っている。
            ・triangile attentionとaxial attentionって同じだと思うのだが。対角成分が入っているかみたいな違い?
            ・axial attentionとbiaxial attentionは違うのか。
        c. 構造予測モジュールではAF2がIPAを, RFはSE3-equivariant Transformer[3]を使っている。
        d. RFでは2-track部分が8層, 3-track部分が4層なのに対し, AF2は4層のfull-MSA evoformerと48層のclustered-msa evoformerからなる。
            ・full evoformerとclustered evoformerって何?
    学習手法の違いとしては, 
        a. AF2はrecycling, すなわちあるネットワークからの入力を別のモデルの入力としている。
            ・一度モデルを学習させた後, そのモデルの予測結果を新しいモデルに学習させるというあれ？
        b. 構造のロス関数として「Frame aligned point error(FAPE)」を
        c. データの蒸留: confidenceの高いデータを新しい学習データとして使う
            ・これは予測結果を新しいモデルに学習させる話?だとしたらaは?

    a,cの一部はablation studyとして研究されているが, どれがAF2の高い予測精度に寄与しているのか, 代替手法で同等の精度が達成できるのかについては明らかになっていない。



        ・これらの違いを挙げているということは, おそらくRF1はAF2の論文発表前, CASPのabstractから作ったのか?
RoseTTAFold (RF) 1 was developed before the architecture of AlphaFold2 (AF2) 2 had been made public. While both models were dramatic increases over state-of-the-art protein structure prediction at release, AF2 had considerably higher accuracy overall. RF and AF2 differ in both their architecture and training regimen. In terms of architecture, major differences between RoseTTAFold and AF2 consist of: a) the inclusion of a third "3D structure" track in the RF basic block, b) the use of biaxial attention in the 2D pair track (RF) versus triangle multiplication and triangle attention (AF2), c) the use of the SE3-equivariant transformer 3 , in RF rather than Invariant Point Attention (IPA) in AF2 for computing structural updates, and d) the overall depth of the network, with 8+4 2-track/3-track layers in RF versus 4+48 full-msa/clustered-msa evoformer layers in AF2. In terms of training, AF2 added: a) the idea of "recycling," where inputs from one network pass were fed into the next, with a random number of recycles used as "preconditioning" on each training example, b) the use of frame-aligned point error (FAPE) as the structure loss function, and c) the use of distillation data, where highly confident network outputs were fed in as new training examples. While several of these changes (recycling and distillation) were explored in ablation studies 2 , it is unclear which features are critical for the high accuracy of AF2, and whether an alternate architecture could achieve comparable accuracy.
    RoseTTAFold（RF）1は、AlphaFold2（AF2）2のアーキテクチャが公開される前に開発された。両モデルとも、リリース時には最先端のタンパク質構造予測よりも飛躍的に向上していたが、全体的な精度はAF2の方がかなり高かった。RFとAF2は、そのアーキテクチャとトレーニング方法の両方で異なっている。アーキテクチャーに関しては、RoseTTAFoldとAF2の主な違いは以下の通りである： a)RFの基本ブロックに3つ目の「3D構造」トラックが含まれていること、b)2Dペアトラックで2軸注意(RF)と三角形の乗算と三角形注意(AF2)を使い分けていること、c)RFではInvariant PointではなくSE3-equivariant transformer 3 、 c)構造更新の計算には、AF2のInvariant Point Attention(IPA)ではなく、RFのSE3-equivariant transformer 3 、d)ネットワークの全体的な深さ、RFの8+4 2-track/3-track層に対して、AF2の4+48 full-msa/clustered-msaエボフォーマ層。学習に関しては、AF2には、a)「リサイクル」という考え方が追加され、1つのネットワークパスからの入力が、各トレーニング例の「事前調整」として使用されるランダムな数のリサイクルで、次のネットワークに供給された。b)構造損失関数としてフレーム整列点誤差（FAPE）の使用、c)蒸留データの使用、つまり、確信度の高いネットワーク出力が新しいトレーニング例として供給された。これらの変化のいくつか（再利用と蒸留）はアブレーション研究で検討されているが2、どの機能がAF2の高精度に不可欠なのか、また別の構造で同等の精度を達成できるのかは不明である。


With the full release of the AF2 method, we set out to combine the best features of both models, and to determine what features were required for the remarkable AF2 prediction accuracy. We reasoned that by adding in features from AF2 one by one, and assessing whether prediction accuracy increased, we could distinguish those that were essential to high accuracy prediction. Since the original publication of RF and AF2, multiple methods for accurate protein structure modeling have been described that essentially re-use the exact AF2 architecture with some modification of inputs: OpenFold 4 is a reimplementation of AF2; ESMFold 5 replaces the multiple sequence alignment (MSA) with a language model generating a single featurized sequence; OmegaFold 6 develops a new pair-to-pair update as a simplified version of triangle attention but makes use of IPA; and UniFold 7 uses AF2 architecture with modifications to loss and auxiliary heads. We reasoned that building a new model from scratch would provide more insight into the critical determinants of accurate structure prediction and guide future efforts in this field; we also aimed for improvements in efficiency and to develop a single model with state of the performance on both monomer and assembly prediction. The resultant model, RoseTTAFold2 (RF2) is a single model equivalent in accuracy to AF2 for monomers and AF2- multimer for complexes, with better computational scaling on proteins and complexes larger than 1000 residues. Finally, our RF2 model – along with inference and training code – is made freely available.
    AF2メソッドのフルリリースに伴い、私たちは両モデルの優れた特徴を組み合わせ、AF2の顕著な予測精度に必要な特徴を見極めることに着手しました。AF2の特徴を1つずつ追加し、予測精度が向上するかどうかを評価することで、高精度の予測に不可欠な特徴を見分けることができると考えたからだ。RFとAF2の最初の発表以来、精度の高いタンパク質構造モデリングのための複数の手法が報告されており、それらは基本的にAF2のアーキテクチャーをそのまま再利用している： OpenFold 4はAF2の再実装であり、ESMFold 5は多重配列アライメント（MSA）を単一のフィーチャー化された配列を生成する言語モデルに置き換えたものである。OmegaFold 6は三角形の注意を簡略化したものとして新しい対対更新を開発したが、IPAを利用している。我々は、新しいモデルをゼロから構築することで、正確な構造予測の重要な決定要因に関するより深い洞察を得ることができ、この分野における将来の取り組みの指針となると考えた。また、効率性の向上と、モノマーとアセンブリの両方の予測において、最新の性能を持つ単一のモデルを開発することを目指した。その結果、RoseTTAFold2(RF2)は、単量体ではAF2、複合体ではAF2- multimerと同等の精度を持ち、1000残基以上のタンパク質や複合体では、より優れた計算スケーリングが可能になりました。最後に、我々のRF2モデルは、推論とトレーニングコードとともに、フリーで利用可能である。
